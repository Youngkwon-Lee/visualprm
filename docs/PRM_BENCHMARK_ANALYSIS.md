# Process Reward Model (PRM) ë²¤ì¹˜ë§ˆí¬ ë¶„ì„ ì¢…í•© ë³´ê³ ì„œ

**ìž‘ì„±ì¼**: 2025-01-08
**ëª©ì **: Med-PRM ë° VisualPRM ë²¤ì¹˜ë§ˆí¬ êµ¬ì¶• ë°©ë²•ë¡  ë¶„ì„ ë° ì˜ë£Œ ë©€í‹°ëª¨ë‹¬ PRM ë²¤ì¹˜ë§ˆí¬ ì„¤ê³„

---

## ðŸ“‹ ëª©ì°¨

1. [ê°œìš”](#1-ê°œìš”)
2. [VisualPRM ë²¤ì¹˜ë§ˆí¬ ë¶„ì„](#2-visualprm-ë²¤ì¹˜ë§ˆí¬-ë¶„ì„)
3. [Med-PRM ë²¤ì¹˜ë§ˆí¬ ë¶„ì„](#3-med-prm-ë²¤ì¹˜ë§ˆí¬-ë¶„ì„)
4. [ë¹„êµ ë¶„ì„](#4-ë¹„êµ-ë¶„ì„)
5. [ì˜ë£Œ ë©€í‹°ëª¨ë‹¬ PRM ì„¤ê³„ì•ˆ](#5-ì˜ë£Œ-ë©€í‹°ëª¨ë‹¬-prm-ì„¤ê³„ì•ˆ)
6. [ì°¸ê³  ìžë£Œ](#6-ì°¸ê³ -ìžë£Œ)

---

## 1. ê°œìš”

### 1.1 Process Reward Model (PRM)ì´ëž€?

**ì •ì˜**: ì¶”ë¡  ê³¼ì •ì˜ ê° ë‹¨ê³„ë³„ë¡œ ë³´ìƒì„ í‰ê°€í•˜ëŠ” ëª¨ë¸

```
Outcome Reward Model (ORM)
â””â”€ ìµœì¢… ë‹µë§Œ í‰ê°€ â†’ ë‹¨ìˆœí•˜ì§€ë§Œ í”¼ë“œë°± ë¶€ì¡±

Process Reward Model (PRM)
â””â”€ ê° ë‹¨ê³„ë³„ í‰ê°€ â†’ ì„¸ë°€í•˜ì§€ë§Œ ì–´ë…¸í…Œì´ì…˜ ë¹„ìš© ë†’ìŒ
```

### 1.2 ì—°êµ¬ ë°°ê²½

| ì—°êµ¬ | ë°œí‘œ | ëª¨ë‹¬ë¦¬í‹° | ë„ë©”ì¸ |
|------|------|----------|--------|
| PRM800K | ICLR 2024 | í…ìŠ¤íŠ¸ | ìˆ˜í•™ |
| Math-Shepherd | arXiv 2023 | í…ìŠ¤íŠ¸ | ìˆ˜í•™ |
| **Med-PRM** | **EMNLP 2025** | **í…ìŠ¤íŠ¸** | **ì˜ë£Œ** |
| **VisualPRM** | **arXiv 2025.03** | **ë©€í‹°ëª¨ë‹¬** | **ì¼ë°˜** |

### 1.3 ë³¸ ë¶„ì„ì˜ ëª©í‘œ

```
Med-PRM (ì˜ë£Œ í…ìŠ¤íŠ¸)
    +
VisualPRM (ì¼ë°˜ ë©€í‹°ëª¨ë‹¬)
    â†“
ì˜ë£Œ ë©€í‹°ëª¨ë‹¬ PRM ë²¤ì¹˜ë§ˆí¬ ì„¤ê³„
```

---

## 2. VisualPRM ë²¤ì¹˜ë§ˆí¬ ë¶„ì„

### 2.1 í•µì‹¬ ê¸°ì—¬

1. **VisualPRM400K** ë°ì´í„°ì…‹: ~400K ìƒ˜í”Œ, 2M ë‹¨ê³„
2. **VisualProcessBench**: 2,866 ìƒ˜í”Œ, 26,950 ì¸ê°„ ë ˆì´ë¸”
3. **ì„±ëŠ¥**: InternVL2.5-78Bì— +5.9ì  í–¥ìƒ (7ê°œ ë²¤ì¹˜ë§ˆí¬)

### 2.2 ë°ì´í„° êµ¬ì¶• ì „ëžµ

#### 2.2.1 ì´ì¤‘ ë°ì´í„°ì…‹ êµ¬ì¡°

```
í•™ìŠµìš©: VisualPRM400K
â”œâ”€ ëª©ì : ëŒ€ê·œëª¨ PRM í•™ìŠµ
â”œâ”€ ë°©ë²•: Monte Carlo ìžë™ ìƒì„±
â”œâ”€ ê·œëª¨: 400K ìƒ˜í”Œ
â””â”€ ë¹„ìš©: ê³„ì‚° ë¹„ìš©ë§Œ

í‰ê°€ìš©: VisualProcessBench
â”œâ”€ ëª©ì : ì •í™•í•œ PRM ì„±ëŠ¥ í‰ê°€
â”œâ”€ ë°©ë²•: ì¸ê°„ ì „ë¬¸ê°€ ì–´ë…¸í…Œì´ì…˜
â”œâ”€ ê·œëª¨: 2,866 ìƒ˜í”Œ
â””â”€ ë¹„ìš©: $1,443 (39 person-days)
```

#### 2.2.2 VisualPRM400K ìžë™ ìƒì„±

**Monte Carlo ê¸°ë°˜ Expected Accuracy**:

```python
# í•µì‹¬ ì•Œê³ ë¦¬ì¦˜
for each step s_i in solution:
    # 16ê°œ continuation ìƒ˜í”Œë§
    continuations = sample_continuations(
        image=I,
        question=q,
        prefix=s_[:i],
        num_samples=16
    )

    # Expected accuracy ê³„ì‚°
    mc_i = sum(is_correct(c) for c in continuations) / 16

    # ë ˆì´ë¸”ë§
    if mc_i > 0:
        label_i = "Correct (+)"
    else:
        label_i = "Incorrect (-)"
```

**ë°ì´í„° í†µê³„**:
- ì´ ìƒ˜í”Œ: ~400K
- ì´ ë‹¨ê³„: ~2M
- í‰ê·  ì‘ë‹µ ê¸¸ì´: 126.9 ë‹¨ì–´
- í‰ê·  ë‹¨ê³„ ìˆ˜: 5.6
- í‰ê·  ë‹¨ê³„ ê¸¸ì´: 22.6 ë‹¨ì–´
- ì˜¤ë‹µ ë‹¨ê³„ ë¹„ìœ¨: ~10%

**ì†ŒìŠ¤ ë°ì´í„°**:
```python
source_benchmarks = {
    "MMPR v1.1": "ì „ì²´",  # ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ 
}

generation_models = [
    "InternVL2.5-8B",
    "InternVL2.5-26B",
    "InternVL2.5-78B"
]
```

#### 2.2.3 VisualProcessBench ì¸ê°„ ì–´ë…¸í…Œì´ì…˜

**ë°ì´í„° ìˆ˜ì§‘**:

| ì†ŒìŠ¤ | ìƒ˜í”Œ ìˆ˜ |
|------|---------|
| MMMU | 267 |
| MathVision | 712 |
| MathVerse | 1,026 |
| DynaMath | 570 |
| WeMath | 291 |
| **ì´ê³„** | **2,866** |

**ì†”ë£¨ì…˜ ìƒì„±**:

| ëª¨ë¸ | ì†”ë£¨ì…˜ ìˆ˜ |
|------|----------|
| GPT-4o | 870 |
| Claude-3.5-Sonnet | 865 |
| QvQ-72B-Preview | 825 |
| InternVL2.5-78B | 306 |

**ì–´ë…¸í…Œì´ì…˜ í”„ë¡œí† ì½œ**:

```yaml
ì–´ë…¸í…Œì´í„°:
  ìžê²©: ìµœì†Œ ëŒ€í•™ í•™ìœ„ ì†Œì§€ìž
  ì¸ì›: 13ëª…
  ê¸°ê°„: 3ì¼
  ì´ ìž‘ì—…ëŸ‰: 39 person-days
  ë¹„ìš©: ~$37/person-day

ìž‘ì—… ë‹¨ìœ„:
  ë¶„í•  ìˆ˜: 10ê°œ
  ìƒ˜í”Œ/ë¶„í• : ~300ê°œ

í’ˆì§ˆ ê´€ë¦¬:
  ê° ë¶„í•  ê²€í† : 10%
  ê²€í† ìž: ë…¼ë¬¸ ì €ìž
  ìž¬ìž‘ì—…: ì˜¤ë¥˜ ë°œê²¬ ì‹œ ì „ì²´ ë¶„í• 

ë ˆì´ë¸” ì²´ê³„:
  - Positive (+): ë‹¨ê³„ê°€ ì •í™•í•¨
  - Negative (-): ë‹¨ê³„ì— ì˜¤ë¥˜ ìžˆìŒ
  - Neutral: ì¶”ë¡  ì—†ìŒ/ì •ë³´ ì¶”ê°€ ì—†ìŒ

í˜ì‹ ì :
  - ê¸°ì¡´: ì²« ì˜¤ë¥˜ë§Œ ì°¾ê¸°
  - VisualPRM: ëª¨ë“  ì˜¤ë¥˜ ì°¾ê¸° (reflection ëŠ¥ë ¥ í‰ê°€)
```

**í†µê³„**:
- ì´ ë‹¨ê³„: 26,950
- ì •ë‹µ ë‹¨ê³„: 16,585 (61.5%)
- ì˜¤ë‹µ ë‹¨ê³„: 7,691 (28.5%)
- ì¤‘ë¦½ ë‹¨ê³„: 2,674 (10%)
- í‰ê·  ë‹¨ê³„/ì†”ë£¨ì…˜: 9.4

### 2.3 í‰ê°€ ë©”íŠ¸ë¦­

**Macro F1 Score**:
```python
# ë¶ˆê· í˜• ë°ì´í„° ëŒ€ì‘
F1_positive = compute_f1(positive_steps)
F1_negative = compute_f1(negative_steps)
Macro_F1 = (F1_positive + F1_negative) / 2

# VisualPRM ì„±ëŠ¥
VisualPRM_8B: 62.0
GPT-4o: 60.3
Random: 50.0
```

### 2.4 VisualPRM ëª¨ë¸ í•™ìŠµ

**ì•„í‚¤í…ì²˜**:
```
Multi-turn Chat í˜•ì‹
â”œâ”€ Turn 0: ì´ë¯¸ì§€ + ì§ˆë¬¸ + ì²« ë‹¨ê³„
â”œâ”€ Turn 1: ë‘ ë²ˆì§¸ ë‹¨ê³„
â””â”€ Turn n: në²ˆì§¸ ë‹¨ê³„
    â†“
ê° turnë§ˆë‹¤ ë‹¨ê³„ ì •í™•ì„± ì˜ˆì¸¡ (+/-)
```

**í•™ìŠµ ì„¤ì •**:
- Base Model: InternVL2.5-8B
- Optimizer: AdamW (Î²1=0.9, Î²2=0.999, weight_decay=0.05)
- Learning Rate: 1e-5 (cosine decay)
- Warmup: 5% of training steps
- Epoch: 1
- Data Packing: í™œì„±í™”

**Value-based PRM vs Advantage-based PRM**:

| íƒ€ìž… | ì •ì˜ | ë ˆì´ë¸” | ì„±ëŠ¥ |
|------|------|--------|------|
| Value-based | mc_i > 0 | +/- | **ë” ë†’ìŒ** |
| Advantage-based | mc_i - mc_{i-1} > 0 | +/=/- | ë‚®ìŒ |

**ì¶”ë¡  ì‹œ ì ìˆ˜ ì§‘ê³„**:
```python
# Step score
step_score_i = P("+") * 1 + P("-") * 0

# Response score (ì—¬ëŸ¬ ë°©ë²•)
response_score = mean(step_scores)      # ìµœì 
# response_score = min(step_scores)     # ë³´ìˆ˜ì 
# response_score = max(step_scores)     # ë‚™ê´€ì  (ì„±ëŠ¥ ë‚®ìŒ)
```

### 2.5 Best-of-N í‰ê°€ ê²°ê³¼

**InternVL2.5-8B ì„±ê³¼** (N=8):

| ë²¤ì¹˜ë§ˆí¬ | Pass@1 | BoN w/ VisualPRM | í–¥ìƒ |
|---------|--------|------------------|------|
| MMMU | 56.2 | 60.2 | +4.0 |
| MathVista | 64.5 | 68.5 | +4.0 |
| MathVision | 17.0 | 25.7 | +8.7 |
| MathVerse-VO | 22.8 | 35.8 | +13.0 |
| DynaMath | 9.4 | 18.0 | +8.6 |
| WeMath | 23.5 | 36.5 | +13.0 |
| LogicVista | 36.0 | 43.8 | +7.8 |
| **Overall** | **32.8** | **41.2** | **+8.4** |

**í™•ìž¥ì„± (InternVL2.5-78B)**:
- Pass@1: 46.0
- BoN w/ VisualPRM: 51.9
- í–¥ìƒ: +5.9 (ëŒ€í˜• ëª¨ë¸ì—ë„ íš¨ê³¼ì )

---

## 3. Med-PRM ë²¤ì¹˜ë§ˆí¬ ë¶„ì„

### 3.1 í•µì‹¬ ê¸°ì—¬

1. **RAG-as-a-Judge**: ì˜í•™ ë¬¸ì„œ ê¸°ë°˜ ìžë™ ê²€ì¦
2. **ë¹„ìš© íš¨ìœ¨ì„±**: $20ìœ¼ë¡œ 11,678 ë¬¸ì œ ì–´ë…¸í…Œì´ì…˜
3. **ì„±ëŠ¥**: MedQA 80.35% (8B ëª¨ë¸ ìµœì´ˆ 80% ëŒíŒŒ)

### 3.2 í•µì‹¬ ì°¨ë³„ì 

```
VisualPRM (ì¼ë°˜)
â””â”€ Monte Carlo ìƒ˜í”Œë§
    â”œâ”€ ìž¥ì : ìžë™í™”
    â””â”€ ë‹¨ì : ê·¼ê±° ì—†ìŒ

Med-PRM (ì˜ë£Œ)
â””â”€ RAG + LLM-as-a-Judge
    â”œâ”€ ìž¥ì : ì˜í•™ ê·¼ê±° ê¸°ë°˜
    â””â”€ í•œê³„: í…ìŠ¤íŠ¸ë§Œ ê°€ëŠ¥
```

### 3.3 ë°ì´í„° êµ¬ì¶• íŒŒì´í”„ë¼ì¸

#### 3.3.1 ì†ŒìŠ¤ ë°ì´í„°

```python
training_sources = {
    "MedQA": 10178,      # ì „ì²´
    "MedMCQA": 500,      # ìƒ˜í”Œ
    "PubMedQA": 500,     # ìƒ˜í”Œ
    "MMLU-Med": 500      # ìƒ˜í”Œ
}
total_questions = 11678

evaluation_benchmarks = [
    "MedQA-4opt",
    "MedQA-5opt",
    "MedMCQA",
    "MMLU-Med",
    "DDXPlus",
    "AgentClinic-MedQA",
    "AgentClinic-NEJM"
]
```

#### 3.3.2 RAG-as-a-Judge ì–´ë…¸í…Œì´ì…˜

**ì˜í•™ ë¬¸ì„œ ê²€ìƒ‰**:

```python
medical_knowledge_sources = [
    "Clinical Guidelines",    # ìž„ìƒ ê°€ì´ë“œë¼ì¸
    "StatPearls",            # ì˜í•™ êµê³¼ì„œ
    "Medical Textbooks",     # ì „ë¬¸ êµìž¬
    "Rare Disease Corpus"    # í¬ê·€ì§ˆí™˜ DB
]

# í† í° í• ë‹¹
max_sequence_length = 4096
reserved_for_docs = 3072
reserved_for_reasoning = 1024
```

**Gemini-2.0-flash ê¸°ë°˜ ê²€ì¦**:

```python
def rag_judge(question, reasoning_step, retrieved_docs):
    """ì˜í•™ ê·¼ê±° ê¸°ë°˜ ë‹¨ê³„ ê²€ì¦"""

    prompt = f"""
    Clinical Question: {question}

    Medical Evidence:
    {retrieved_docs}

    Reasoning Step:
    {reasoning_step}

    Task: Is this reasoning step medically correct
    based on the evidence?

    Answer: +/- (with citation to evidence)
    """

    response = gemini_2_flash(prompt)
    return response.label, response.citation
```

**í’ˆì§ˆ í•„í„°**:

```yaml
filtering_rules:
  step_count: [3, 9]           # ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ì¶”ë¡  ì œì™¸
  label_balance: true           # ì •ë‹µ/ì˜¤ë‹µ ê· í˜• ìœ ì§€
  degenerate_check: true        # ë°˜ë³µ/ë¬´ì˜ë¯¸ ë‹¨ê³„ ì œê±°
  per_question_correct_limit: true  # ì •ë‹µ ì¶”ë¡  ìˆ˜ ì œí•œ
```

#### 3.3.3 ì¸ê°„ ê²€ì¦ (ìƒ˜í”Œë§)

```python
human_evaluation = {
    "annotators": {
        "physician": "4ë…„ ê²½ë ¥",
        "medical_student_1": "ê³ í•™ë…„",
        "medical_student_2": "ê³ í•™ë…„"
    },

    "sample_design": {
        "easy_questions": 3,
        "hard_questions": 3,
        "traces_per_question": 5
    },

    "total_annotations": 180,  # ë‹¨ê³„ ë ˆì´ë¸”

    "inter_rater_reliability": {
        "physician_vs_model": 0.71,  # Pearson
        "student_vs_model": 0.74
    }
}
```

**í•´ì„**:
- Pearson 0.71-0.74 = ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„
- í•™ìƒì´ ì˜ì‚¬ë³´ë‹¤ ëª¨ë¸ê³¼ ë” ì¼ì¹˜ (í¥ë¯¸ë¡œìš´ ê²°ê³¼)
- ìƒ˜í”Œë§ ê²€ì¦ìœ¼ë¡œ ë¹„ìš© ì ˆê°

### 3.4 í•™ìŠµ ë°ì´í„° ìƒì„±

```python
for question in training_set:
    # 1. 16ê°œ í›„ë³´ ì¶”ë¡  ìƒì„±
    candidate_traces = llm.generate(
        prompt=question,
        num_samples=16,
        temperature=0.7
    )

    # 2. ê° í›„ë³´ì— ëŒ€í•´ ì˜í•™ ë¬¸ì„œ ê²€ìƒ‰
    for trace in candidate_traces:
        docs = retrieve_medical_docs(question)

        # 3. ë‹¨ê³„ë³„ RAG ê²€ì¦
        steps = split_trace(trace, min=3, max=9)
        labels = []

        for step in steps:
            label = gemini_judge(question, step, docs)
            labels.append(label)

        # 4. í•™ìŠµ ìƒ˜í”Œ ì €ìž¥
        training_data.append({
            "question": question,
            "trace": trace,
            "step_labels": labels,
            "evidence": docs
        })
```

### 3.5 ë¹„ìš© ë¶„ì„

```
API ë¹„ìš© (Gemini-2.0-flash):
â”œâ”€ ì´ ë¹„ìš©: ~$20
â”œâ”€ ë¬¸ì œ ìˆ˜: 11,678
â””â”€ ë¹„ìš©/ë¬¸ì œ: ~$0.0017

vs ì¸ê°„ ì–´ë…¸í…Œì´ì…˜:
â”œâ”€ VisualPRM: $1,443 / 2,866 = $0.50/ìƒ˜í”Œ
â”œâ”€ ì˜ë£Œ ì „ë¬¸ê°€ ì¶”ì •: ~$5-10/ìƒ˜í”Œ
â””â”€ Med-PRM ì ˆê°: 99%+
```

### 3.6 ì„±ëŠ¥ ê²°ê³¼

**MedQA (4-option)**:

| ëª¨ë¸ | í¬ê¸° | ì •í™•ë„ |
|------|------|--------|
| GPT-4 | - | 78.9% |
| Med-Gemini | - | 79.5% |
| **Meerkat-8B + Med-PRM** | **8B** | **80.35%** |

**íŠ¹ì´ì‚¬í•­**:
- 8B ëª¨ë¸ë¡œ ìµœì´ˆ 80% ëŒíŒŒ
- ê¸°ì¡´ ëŒ€í˜• ìƒìš© ëª¨ë¸ ì´ˆê³¼

**ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì„±ëŠ¥**:
- 7ê°œ ì¤‘ 6ê°œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ SOTA
- ë² ì´ìŠ¤ ëª¨ë¸ ëŒ€ë¹„ ìµœëŒ€ +13.50% í–¥ìƒ

---

## 4. ë¹„êµ ë¶„ì„

### 4.1 ì¢…í•© ë¹„êµí‘œ

| ì¸¡ë©´ | Med-PRM | VisualPRM | ì˜ë£Œ ë©€í‹°ëª¨ë‹¬ (ì œì•ˆ) |
|------|---------|-----------|---------------------|
| **ë°œí‘œ** | EMNLP 2025 | arXiv 2025.03 | TBD |
| **ëª¨ë‹¬ë¦¬í‹°** | í…ìŠ¤íŠ¸ | ì´ë¯¸ì§€+í…ìŠ¤íŠ¸ | ì˜ë£Œì˜ìƒ+í…ìŠ¤íŠ¸ |
| **ë„ë©”ì¸** | ì˜ë£Œ | ì¼ë°˜ ì¶”ë¡  | ì˜ë£Œ |
| **ì–´ë…¸í…Œì´ì…˜** | RAG+LLM | Monte Carlo | **í•˜ì´ë¸Œë¦¬ë“œ** |
| **ì˜í•™ ê·¼ê±°** | âœ… í•„ìˆ˜ | âŒ | âœ… í•„ìˆ˜ |
| **í•™ìŠµ ë°ì´í„°** | 11,678 ë¬¸ì œ | 400K ìƒ˜í”Œ | 50K ìƒ˜í”Œ |
| **í‰ê°€ ë°ì´í„°** | 180 ë‹¨ê³„ | 26,950 ë‹¨ê³„ | 5,000 ë‹¨ê³„ |
| **ë¹„ìš©** | $20 | $1,443 | **$620** |
| **ì¸ê°„ ê²€ì¦** | ìƒ˜í”Œë§ (180) | ì „ì²´ (26,950) | ì„ ë³„ì  (5,000) |

### 4.2 ë°©ë²•ë¡  ë¹„êµ

#### 4.2.1 ì–´ë…¸í…Œì´ì…˜ ì „ëžµ

**Monte Carlo (VisualPRM)**:
```python
pros = [
    "ì™„ì „ ìžë™í™”",
    "ëŒ€ê·œëª¨ ìƒì„± ê°€ëŠ¥",
    "ë„ë©”ì¸ ë…ë¦½ì "
]

cons = [
    "ê·¼ê±° ì—†ìŒ",
    "ì˜¤ë‹µ ë¹„ìœ¨ ë‚®ìŒ (10%)",
    "ì˜ë£Œ ë„ë©”ì¸ì— ë¶€ì í•©"
]
```

**RAG-as-a-Judge (Med-PRM)**:
```python
pros = [
    "ì˜í•™ ê·¼ê±° ì œê³µ",
    "ë¹„ìš© íš¨ìœ¨ì  ($20)",
    "ì „ë¬¸ê°€ ì§€ì‹ ë°˜ì˜"
]

cons = [
    "í…ìŠ¤íŠ¸ë§Œ ê°€ëŠ¥",
    "ê²€ìƒ‰ í’ˆì§ˆ ì˜ì¡´",
    "LLM API ë¹„ìš©"
]
```

#### 4.2.2 í’ˆì§ˆ ê´€ë¦¬

| ë°©ë²• | Med-PRM | VisualPRM |
|------|---------|-----------|
| **ìžë™ í•„í„°** | ë‹¨ê³„ ìˆ˜, ê· í˜•, í‡´í™” | ì—†ìŒ |
| **ì¸ê°„ ê²€ì¦** | 180 ìƒ˜í”Œ (0.015%) | ì „ì²´ (100%) |
| **ê²€ì¦ ì§€í‘œ** | Pearson ìƒê´€ê³„ìˆ˜ | Macro F1 |
| **ìž¬í˜„ì„±** | ë†’ìŒ (RAG ê²°ì •ì ) | ì¤‘ê°„ (MC í™•ë¥ ì ) |

### 4.3 ì ìš© ì‹œë‚˜ë¦¬ì˜¤

```
ì‹œë‚˜ë¦¬ì˜¤ 1: ì˜ë£Œ í…ìŠ¤íŠ¸ QA
â”œâ”€ ìµœì : Med-PRM
â””â”€ ì´ìœ : RAGë¡œ ê·¼ê±° í™•ë³´, ì €ë¹„ìš©

ì‹œë‚˜ë¦¬ì˜¤ 2: ì¼ë°˜ ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ 
â”œâ”€ ìµœì : VisualPRM
â””â”€ ì´ìœ : Monte Carloë¡œ ëŒ€ê·œëª¨ ìƒì„±

ì‹œë‚˜ë¦¬ì˜¤ 3: ì˜ë£Œ ì˜ìƒ ì§„ë‹¨
â”œâ”€ ìµœì : í•˜ì´ë¸Œë¦¬ë“œ (ì œì•ˆ)
â””â”€ ì´ìœ : RAG(ê·¼ê±°) + MC(ì˜ìƒ) + ì¸ê°„(ì„ ë³„)
```

---

## 5. ì˜ë£Œ ë©€í‹°ëª¨ë‹¬ PRM ì„¤ê³„ì•ˆ

### 5.1 ì„¤ê³„ ì² í•™

```
Med-PRMì˜ ìž¥ì  (ì˜í•™ ê·¼ê±°)
    +
VisualPRMì˜ ìž¥ì  (ë©€í‹°ëª¨ë‹¬)
    +
ë¹„ìš© ìµœì í™” (ì„ ë³„ì  ì¸ê°„ ê²€ì¦)
    =
ì˜ë£Œ ë©€í‹°ëª¨ë‹¬ PRM
```

### 5.2 í•˜ì´ë¸Œë¦¬ë“œ ì–´ë…¸í…Œì´ì…˜ íŒŒì´í”„ë¼ì¸

```python
def medical_multimodal_annotation(image, question, solution):
    """3ë‹¨ê³„ í•˜ì´ë¸Œë¦¬ë“œ ì–´ë…¸í…Œì´ì…˜"""

    # ===== Stage 1: RAG-Judge (Med-PRM) =====
    medical_docs = retrieve_medical_evidence(
        image=image,
        question=question,
        sources=[
            "radiology_atlas",
            "pathology_guidelines",
            "clinical_protocols",
            "case_reports"
        ],
        max_tokens=3072
    )

    rag_labels = gemini_2_flash_judge(
        image=image,
        question=question,
        solution=solution,
        evidence=medical_docs
    )

    # ===== Stage 2: Monte Carlo (VisualPRM) =====
    mc_scores = []
    for i, step in enumerate(solution.steps):
        continuations = []
        for _ in range(32):  # ì˜ë£ŒëŠ” ë” ë§Žì´
            cont = medical_mllm.generate(
                image=image,
                prefix=solution.steps[:i+1],
                temperature=0.7
            )
            continuations.append(cont)

        mc_i = sum(is_correct(c) for c in continuations) / 32
        mc_scores.append(mc_i)

    # ===== Stage 3: Hybrid Labeling =====
    final_labels = []
    uncertain_steps = []

    for idx, (rag, mc) in enumerate(zip(rag_labels, mc_scores)):
        if rag == "+" and mc > 0.7:
            label = "confident_correct"
            confidence = min(mc, 0.95)

        elif rag == "-" and mc < 0.3:
            label = "confident_incorrect"
            confidence = min(1 - mc, 0.95)

        else:
            # ë¶ˆì¼ì¹˜ ì¼€ì´ìŠ¤ â†’ ì¸ê°„ ê²€ì¦ í•„ìš”
            label = "uncertain"
            confidence = 0.5
            uncertain_steps.append(idx)

        final_labels.append({
            "label": label,
            "confidence": confidence,
            "rag_label": rag,
            "mc_score": mc,
            "medical_evidence": medical_docs
        })

    # ===== Stage 4: Expert Verification (ì„ ë³„ì ) =====
    if uncertain_steps:
        expert_labels = medical_expert_annotation(
            image=image,
            question=question,
            solution=solution,
            uncertain_indices=uncertain_steps,
            evidence=medical_docs
        )

        # ë¶ˆí™•ì‹¤í•œ ë‹¨ê³„ë§Œ ì „ë¬¸ê°€ ë ˆì´ë¸”ë¡œ ëŒ€ì²´
        for idx, expert_label in zip(uncertain_steps, expert_labels):
            final_labels[idx] = expert_label

    return final_labels, medical_docs
```

### 5.3 ë¹„ìš© ìµœì í™”

**ë‹¨ê³„ë³„ ë¹„ìš©**:

| ë‹¨ê³„ | ë°©ë²• | ì²˜ë¦¬ëŸ‰ | ë¹„ìš© | í’ˆì§ˆ |
|------|------|--------|------|------|
| 1 | RAG-Judge | ì „ì²´ | $20/10K | 70% |
| 2 | Monte Carlo | ì „ì²´ | $100/10K | 85% |
| 3 | í•©ì˜ í™•ì¸ | ì „ì²´ | $0 | - |
| 4 | ì „ë¬¸ê°€ ê²€ì¦ | ë¶ˆì¼ì¹˜ë§Œ (~30%) | $500/10K | 98% |
| **ì´í•©** | **í•˜ì´ë¸Œë¦¬ë“œ** | - | **$620/10K** | **95%** |

**vs ê¸°ì¡´ ë°©ë²•**:
- ì „ì²´ ì „ë¬¸ê°€: $5,000/10K (87% ì ˆê°)
- VisualPRM: $1,443/2.9K â†’ $5,000/10K (88% ì ˆê°)
- Med-PRM: $20/10K (but í…ìŠ¤íŠ¸ë§Œ)

### 5.4 ë°ì´í„°ì…‹ êµ¬ì„±

```python
medical_multimodal_prm_dataset = {
    "training": {
        "chest_xray": {
            "samples": 20000,
            "annotation": "hybrid",
            "sources": ["MIMIC-CXR", "CheXpert"],
            "cost": "$400"
        },
        "ct_scan": {
            "samples": 10000,
            "annotation": "hybrid",
            "sources": ["RadImageNet", "LiTS"],
            "cost": "$200"
        },
        "pathology": {
            "samples": 10000,
            "annotation": "hybrid",
            "sources": ["PathVQA", "PatchCamelyon"],
            "cost": "$200"
        },
        "clinical_photos": {
            "samples": 5000,
            "annotation": "hybrid",
            "sources": ["Derm7pt", "HAM10000"],
            "cost": "$100"
        },
        "total_training": {
            "samples": 45000,
            "cost": "$900"
        }
    },

    "evaluation": {
        "radiology": {
            "samples": 500,
            "annotation": "expert_verified",
            "specialists": ["radiologist_board_certified"],
            "cost": "$2500"
        },
        "pathology": {
            "samples": 300,
            "annotation": "expert_verified",
            "specialists": ["pathologist_5yr"],
            "cost": "$1500"
        },
        "dermatology": {
            "samples": 200,
            "annotation": "expert_verified",
            "specialists": ["dermatologist"],
            "cost": "$1000"
        },
        "total_evaluation": {
            "samples": 1000,
            "cost": "$5000"
        }
    },

    "grand_total": {
        "training_samples": 45000,
        "evaluation_samples": 1000,
        "total_cost": "$5900",
        "cost_per_sample": "$0.13"
    }
}
```

### 5.5 ë²¤ì¹˜ë§ˆí¬ ìŠ¤í‚¤ë§ˆ

```json
{
  "case_id": "medprm_cxr_0001",
  "modality": "chest_xray",
  "metadata": {
    "source": "MIMIC-CXR",
    "difficulty": "intermediate",
    "specialty": "radiology",
    "requires_specialist": true,
    "irb_approved": true,
    "phi_removed": true
  },

  "clinical_context": {
    "age_group": "60-70",
    "sex": "M",
    "symptoms": ["cough", "fever", "dyspnea"],
    "history": ["smoker_30_pack_years", "copd"],
    "vitals": {
      "temp": "38.5C",
      "spo2": "92%"
    }
  },

  "image": {
    "path": "anonymized/cxr_0001.dcm",
    "view": "PA",
    "quality": "adequate"
  },

  "question": "Describe the radiographic findings and provide a differential diagnosis.",

  "gold_standard": {
    "findings": [
      "Bilateral lower lobe infiltrates",
      "Air bronchograms present",
      "No pleural effusion"
    ],
    "diagnosis": "Community-acquired pneumonia",
    "icd10": "J18.9",
    "confidence": "high"
  },

  "solution_steps": [
    {
      "step_id": 0,
      "category": "observation",
      "content": "Bilateral patchy opacities in the lower lobes",
      "label": "correct",
      "confidence": 0.92,
      "annotation_method": "rag_mc_consensus",
      "rag_label": "+",
      "mc_score": 0.875,
      "medical_evidence": [
        {
          "source": "Fleischner Society Guidelines",
          "quote": "Ground-glass opacities may represent...",
          "relevance": 0.89
        }
      ]
    },
    {
      "step_id": 1,
      "category": "analysis",
      "content": "Pattern consistent with alveolar filling process",
      "label": "correct",
      "confidence": 0.85,
      "annotation_method": "rag_mc_consensus",
      "rag_label": "+",
      "mc_score": 0.78,
      "differential": [
        "pneumonia",
        "pulmonary_edema",
        "hemorrhage"
      ]
    },
    {
      "step_id": 2,
      "category": "integration",
      "content": "Combined with fever and elevated WBC, suggests infection",
      "label": "correct",
      "confidence": 0.95,
      "annotation_method": "expert_verified",
      "rag_label": "+",
      "mc_score": 0.65,
      "expert_id": "radiologist_001",
      "expert_note": "Correct integration of clinical and imaging findings"
    },
    {
      "step_id": 3,
      "category": "diagnosis",
      "content": "Primary diagnosis: Community-acquired pneumonia (CAP)",
      "label": "correct",
      "confidence": 0.90,
      "annotation_method": "rag_mc_consensus",
      "rag_label": "+",
      "mc_score": 0.81,
      "icd10": "J18.9",
      "supporting_guidelines": [
        "IDSA/ATS CAP Guidelines 2019"
      ]
    }
  ],

  "annotation_metadata": {
    "annotation_date": "2025-01-08",
    "rag_model": "gemini-2.0-flash",
    "mc_model": "InternVL2.5-8B",
    "mc_samples": 32,
    "expert_verified_steps": [2],
    "primary_annotator": "hybrid_system",
    "expert_reviewer": "radiologist_001",
    "total_steps": 4,
    "confident_steps": 3,
    "uncertain_steps": 1
  }
}
```

### 5.6 êµ¬í˜„ ë¡œë“œë§µ

```
Phase 1: Prototype (Week 1-2)
â”œâ”€ 50 cases from MIMIC-CXR
â”œâ”€ RAG system setup
â”‚   â”œâ”€ Radiology atlas embedding
â”‚   â””â”€ Gemini API integration
â”œâ”€ Monte Carlo pipeline
â””â”€ 1 radiologist validation

Phase 2: Pilot (Week 3-4)
â”œâ”€ 500 cases (multi-modality)
â”œâ”€ Hybrid annotation
â”œâ”€ 3 specialists (rad/path/derm)
â”œâ”€ IRB submission
â””â”€ Quality metrics (Cohen's Kappa)

Phase 3: Scale-up (Week 5-8)
â”œâ”€ 45,000 training cases
â”œâ”€ 1,000 evaluation cases
â”œâ”€ Expert verification (selective)
â””â”€ Benchmark v1.0 release

Phase 4: Validation (Week 9-12)
â”œâ”€ Baseline model evaluation
â”‚   â”œâ”€ GPT-4V
â”‚   â”œâ”€ Med-Gemini
â”‚   â””â”€ InternVL2.5
â”œâ”€ PRM training
â”œâ”€ Best-of-N evaluation
â”œâ”€ Paper writing
â””â”€ Dataset publication
```

### 5.7 ì˜ˆìƒ ì„±ê³¼

**ì •ëŸ‰ì  ëª©í‘œ**:
```
í•™ìŠµ ë°ì´í„°: 45,000 ì¼€ì´ìŠ¤
í‰ê°€ ë°ì´í„°: 1,000 ì¼€ì´ìŠ¤ (ì „ë¬¸ê°€ ê²€ì¦)
ì´ ë¹„ìš©: $5,900
ë¹„ìš©/ìƒ˜í”Œ: $0.13

ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ ì˜ˆìƒ í–¥ìƒ:
- MedQA: +5-10%
- PathVQA: +10-15%
- RadiologyQA: +8-12%
```

**ì •ì„±ì  ê¸°ì—¬**:
1. ì˜í•™ ê·¼ê±° ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ PRM (ìµœì´ˆ)
2. ë¹„ìš© íš¨ìœ¨ì  í•˜ì´ë¸Œë¦¬ë“œ ì–´ë…¸í…Œì´ì…˜
3. ìž¬í˜„ ê°€ëŠ¥í•œ íŒŒì´í”„ë¼ì¸
4. ì˜¤í”ˆì†ŒìŠ¤ ê³µê°œ

---

## 6. ì°¸ê³  ìžë£Œ

### 6.1 ë…¼ë¬¸

1. **VisualPRM**
   - Title: "VisualPRM: An Effective Process Reward Model for Multimodal Reasoning"
   - Authors: Weiyun Wang et al.
   - arXiv: 2503.10291
   - Date: March 2025

2. **Med-PRM**
   - Title: "Med-PRM: Medical Reasoning Models with Stepwise, Guideline-verified Process Rewards"
   - Authors: ETH Medical AI Lab
   - arXiv: 2506.11474
   - Conference: EMNLP 2025 (Oral)

3. **Math-Shepherd**
   - arXiv: 2312.08935
   - ìµœì´ˆ Monte Carlo PRM

4. **PRM800K**
   - OpenAI
   - ICLR 2024
   - ìµœì´ˆ ëŒ€ê·œëª¨ PRM ë°ì´í„°ì…‹

### 6.2 ë¦¬ì†ŒìŠ¤

**VisualPRM**:
- Paper: https://arxiv.org/abs/2503.10291
- ë°ì´í„°ì…‹: ë…¼ë¬¸ì—ì„œ ê³µê°œ ì˜ˆì •

**Med-PRM**:
- Paper: https://arxiv.org/abs/2506.11474
- GitHub: https://github.com/eth-medical-ai-lab/Med-PRM
- Website: https://med-prm.github.io/
- Model: dmis-lab/llama-3.1-medprm-reward-v1.0 (Hugging Face)
- Dataset: dmis-lab/llama-3.1-medprm-reward-training-set (Hugging Face)

### 6.3 ë²¤ì¹˜ë§ˆí¬

**ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ **:
- MMMU, MathVista, MathVision, MathVerse
- DynaMath, WeMath, LogicVista

**ì˜ë£Œ í…ìŠ¤íŠ¸**:
- MedQA, MedMCQA, PubMedQA, MMLU-Med
- DDXPlus, AgentClinic

**ì˜ë£Œ ë©€í‹°ëª¨ë‹¬ (ì œì•ˆ)**:
- MIMIC-CXR, PathVQA, RadiologyQA
- Derm7pt, CheXpert

---

## ë¶€ë¡

### A. ìš©ì–´ ì •ë¦¬

- **PRM**: Process Reward Model
- **ORM**: Outcome Reward Model
- **RAG**: Retrieval-Augmented Generation
- **BoN**: Best-of-N
- **MC**: Monte Carlo
- **IRB**: Institutional Review Board
- **PHI**: Protected Health Information

### B. ë¹„ìš© ê³„ì‚° ìƒì„¸

```python
# VisualPRM ë¹„ìš©
visualprm_cost = {
    "annotators": 13,
    "days": 3,
    "cost_per_day": 37,
    "total": 13 * 3 * 37  # $1,443
}

# Med-PRM ë¹„ìš©
medprm_cost = {
    "api_calls": 11678 * 16,  # questions * candidates
    "cost_per_1k": "$0.000107",  # Gemini-2.0-flash
    "total": 20  # ~$20
}

# ì œì•ˆ ë°©ë²• ë¹„ìš©
hybrid_cost = {
    "rag_api": 100,
    "monte_carlo_compute": 100,
    "expert_annotation": 420,  # 30% * $1,400
    "total": 620
}
```

### C. ë‹¤ìŒ ë‹¨ê³„ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Med-PRM GitHub ì½”ë“œ ë¶„ì„
- [ ] RAG ì‹œìŠ¤í…œ í”„ë¡œí† íƒ€ìž… êµ¬ì¶•
- [ ] MIMIC-CXR 50 ì¼€ì´ìŠ¤ë¡œ íŒŒì¼ëŸ¿
- [ ] IRB ì‹ ì²­ì„œ ìž‘ì„±
- [ ] ì „ë¬¸ì˜ 3ëª… ì„­ì™¸
- [ ] ë²¤ì¹˜ë§ˆí¬ v0.1 ë¦´ë¦¬ìŠ¤

---

**ë¬¸ì„œ ë²„ì „**: 1.0
**ìµœì¢… ìˆ˜ì •**: 2025-01-08
**ìž‘ì„±ìž**: YK Team
