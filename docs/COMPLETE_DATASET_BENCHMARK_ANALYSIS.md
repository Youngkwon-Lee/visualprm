# ì™„ì „í•œ ì¬í™œ/ë¬¼ë¦¬ì¹˜ë£Œ ë°ì´í„°ì…‹ ë° ë²¤ì¹˜ë§ˆí¬ ë¶„ì„

**ì‘ì„±ì¼**: 2026-01-08
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2026-01-08 23:30
**ëª©ì **: PhysioMM-PRM ì œì•ˆ ì „ í¬ê´„ì  ê²½ìŸ ë¶„ì„

---

## Executive Summary

### í•µì‹¬ ë°œê²¬

âœ… **ì¬í™œ ìš´ë™ ë°ì´í„°ì…‹**: **11ê°œ ë°œê²¬** (2016-2025)
âœ… **ì˜ë£Œ VQA ë²¤ì¹˜ë§ˆí¬**: **5ê°œ ì¡´ì¬** (ì •ì  ì´ë¯¸ì§€ ì¤‘ì‹¬)
âœ… **Process Reward Model ë²¤ì¹˜ë§ˆí¬**: **VisualPRM ì¡´ì¬** (2024, ì¼ë°˜ ë„ë©”ì¸)
âŒ **ë¬¼ë¦¬ì¹˜ë£Œ ë„ë©”ì¸ PRM**: **ì „ë¬´** â­
âŒ **ë¹„ë””ì˜¤ ê¸°ë°˜ ì„ìƒ ì¶”ë¡  í‰ê°€**: **ì „ë¬´** â­

### ìµœì¢… ê²°ë¡ 

**PhysioMM-PRMì€ ë¬¼ë¦¬ì¹˜ë£Œ ë„ë©”ì¸ì˜ ì„¸ê³„ ìµœì´ˆ Process Reward Model ë²¤ì¹˜ë§ˆí¬**ì…ë‹ˆë‹¤.

---

## Part 1: ì¬í™œ ìš´ë™ ë°ì´í„°ì…‹ (11ê°œ)

### 1.1 ëŒ€ê·œëª¨ Action Recognition ë°ì´í„°ì…‹

#### ğŸ† NTU RGB+D (CVPR 2016) - **ê°€ì¥ ë§ì´ ì¸ìš©ë¨**

**ì¶œì²˜**:
- [NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis (CVPR 2016)](https://arxiv.org/abs/1604.02808)
- [GitHub - shahroudy/NTURGB-D](https://github.com/shahroudy/NTURGB-D)
- [ROSE Lab - Action Recognition Datasets](https://rose1.ntu.edu.sg/dataset/actionRecognition/)

**ê·œëª¨**:
- **56,880 videos**, 4M frames
- **60 action classes** (daily, mutual, medical conditions)
- 40 subjects
- 3 Kinect V2 cameras

**ì¸ìš© ìˆ˜**: **4,000+ citations** (Google Scholar)

**íŠ¹ì§•**:
- âœ… Multi-modality: RGB + Depth + 3D Skeleton + IR
- âœ… **ì˜ë£Œ ê´€ë ¨ actions í¬í•¨**
- âœ… ì„¸ê³„ í‘œì¤€ action recognition ë²¤ì¹˜ë§ˆí¬
- âœ… Public dataset

**í‰ê°€ ë°©ì‹**:
- Action classification accuracy
- âŒ **ì¬í™œ ì „ë¬¸ ì•„ë‹˜** (general action recognition)
- âŒ **VQA í˜•ì‹ ì•„ë‹˜**
- âŒ **ë‹¨ê³„ë³„ ì¶”ë¡  í‰ê°€ ì—†ìŒ**

---

#### ğŸ† NTU RGB+D 120 (TPAMI 2020) - **ê°€ì¥ í° ê·œëª¨**

**ì¶œì²˜**: [NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding](https://arxiv.org/abs/1905.04757)

**ê·œëª¨**:
- **114,480 videos**, 8M frames ğŸ”¥
- **120 action classes**
- 106 subjects
- RGB (1920Ã—1080) + Depth + Skeleton + IR

**ì¸ìš© ìˆ˜**: **2,000+ citations**

**íŠ¹ì§•**:
- âœ… **ì„¸ê³„ ìµœëŒ€ ê·œëª¨** action recognition ë°ì´í„°ì…‹
- âœ… Skeleton-based action recognition SOTA ë²¤ì¹˜ë§ˆí¬
- âœ… [Papers with Code - 83ê°œ ëª¨ë¸ ë¹„êµ](https://paperswithcode.com/sota/skeleton-based-action-recognition-on-ntu-rgbd-1)

**í‰ê°€ ë°©ì‹**:
- Cross-subject, Cross-setup accuracy
- âŒ **ì¬í™œ ì „ë¬¸ ì•„ë‹˜**
- âŒ **VQA í˜•ì‹ ì•„ë‹˜**

---

### 1.2 ì¬í™œ ì „ë¬¸ ë°ì´í„°ì…‹

#### ğŸ† KIMORE (TNSRE 2019) - **ì¬í™œ ë¶„ì•¼ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬**

**ì¶œì²˜**: [The KIMORE Dataset: KInematic Assessment of MOvement and Clinical Scores](https://www.researchgate.net/publication/333791841_The_KIMORE_Dataset_KInematic_Assessment_of_MOvement_and_Clinical_Scores_for_Remote_Monitoring_of_Physical_REhabilitation)

**ê·œëª¨**:
- **78 subjects** (44 healthy + **34 motor dysfunction patients**)
- **5 exercises** (low back pain ì¬í™œ ì „ë¬¸)
- RGB + Depth + Skeleton (Kinect v2)

**ì¸ìš© ìˆ˜**: **300+ citations**

**íŠ¹ì§•**:
- âœ… **ì‹¤ì œ í™˜ì ë°ì´í„°**
- âœ… **ì„ìƒ ì„¤ë¬¸ì§€ í¬í•¨** (physician evaluations)
- âœ… **ì˜ì‚¬ê°€ ì„ ì •í•œ ìš´ë™**
- âœ… Free dataset
- âœ… **ì¬í™œ ì—°êµ¬ì—ì„œ ìì£¼ ì¸ìš©ë¨**

**í‰ê°€ ë°©ì‹**:
- Clinical questionnaire scores
- Kinematic features
- âŒ **VQA í˜•ì‹ ì•„ë‹˜**
- âŒ **ë‹¨ê³„ë³„ ì¶”ë¡  ì—†ìŒ**

---

#### REHAB24-6 (2024ë…„ 8ì›”) - **ìµœì‹ **

**ì¶œì²˜**: [REHAB24-6: A multi-modal dataset of physical rehabilitation exercises](https://zenodo.org/records/13305826)

**ê·œëª¨**:
- 65 recordings, **184,825 frames** (30 FPS)
- 10 subjects
- 6 exercises, 1,072 repetitions
- 2 cameras (multi-view)

**íŠ¹ì§•**:
- âœ… **Correct/Incorrect execution êµ¬ë¶„**
- âœ… 3D motion capture + RGB
- âœ… Temporal segmentation
- âœ… Zenodo ê³µê°œ ë‹¤ìš´ë¡œë“œ
- âœ… "Most comprehensive testbed for exercise-correctness tasks"

**í‰ê°€ ë°©ì‹**:
- Binary correctness (correct/incorrect)
- âŒ **ë‹¨ê³„ë³„ ì¶”ë¡  ì—†ìŒ**
- âŒ **VQA í˜•ì‹ ì•„ë‹˜**

---

#### TheraPose (2024ë…„ 5ì›”)

**ì¶œì²˜**: [TheraPose: A Large Video Dataset for Physiotherapy Exercises](https://www.researchgate.net/publication/386380810_TheraPose_A_Large_Video_Dataset_for_Physiotherapy_Exercises)

**ê·œëª¨**:
- **3,424,125 frames** ğŸ”¥
- **123 exercises** (ê°€ì¥ ë‹¤ì–‘í•œ ìš´ë™)
- Motion capture + high-resolution video

**íŠ¹ì§•**:
- âœ… ë§¤ìš° í° ê·œëª¨
- âš ï¸ **Sample subsetë§Œ ê³µê°œ** (full dataset ë¹„ê³µê°œ)

**í‰ê°€ ë°©ì‹**:
- Motion capture ê¸°ë°˜ ì •ëŸ‰ í‰ê°€
- âŒ **VQA í˜•ì‹ ì•„ë‹˜**

---

#### UCO Physical Rehabilitation (2023ë…„ 10ì›”)

**ì¶œì²˜**:
- [UCO Physical Rehabilitation: New Dataset and Study](https://www.mdpi.com/1424-8220/23/21/8862)
- [GitHub - AVAuco/ucophyrehab](https://github.com/AVAuco/ucophyrehab)

**ê·œëª¨**:
- 27 subjects
- **2,160 video sequences** (í‰ê·  30.4ì´ˆ, ~1.6M frames)
- 5 RGB cameras (multi-view)
- 8 exercises (í•˜ì§€ 4ê°œ + ìƒì§€ 4ê°œ)

**íŠ¹ì§•**:
- âœ… GitHub ê³µê°œ
- âœ… Multi-view
- âœ… Pose estimation baseline ì œê³µ

**í‰ê°€ ë°©ì‹**:
- Pose estimation accuracy
- âŒ **ì„ìƒ í‰ê°€ ì—†ìŒ**

---

#### FineRehab (CVPR 2024) - **ìµœì‹  AQA**

**ì¶œì²˜**: [FineRehab: A Multi-modality and Multi-task Dataset for Rehabilitation Analysis](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Li_FineRehab_A_Multi-modality_and_Multi-task_Dataset_for_Rehabilitation_Analysis_CVPRW_2024_paper.pdf)

**ê·œëª¨**:
- **16 exercises**
- **50 participants**
- **4,215 files**
- 2 Kinect RGB-D + 17 IMUs

**íŠ¹ì§•**:
- âœ… **Multi-modality** (RGB-D + IMU)
- âœ… **Multi-task** (ì—¬ëŸ¬ í‰ê°€ ì‘ì—…)
- âœ… CVPR 2024 (ìµœì‹ )
- âœ… Action Quality Assessment (AQA) ë°©ì‹

**í‰ê°€ ë°©ì‹**:
- Fine-grained quality scoring
- âŒ **VQA í˜•ì‹ ì•„ë‹˜**
- âŒ **ë‹¨ê³„ë³„ ì¶”ë¡  ì—†ìŒ**

---

#### LLM-FMS (2025ë…„ 3ì›”) - **LLM í†µí•©**

**ì¶œì²˜**: [LLM-FMS: A fine-grained dataset for functional movement screen](https://pmc.ncbi.nlm.nih.gov/articles/PMC11896072/)

**ê·œëª¨**:
- **1,812 action keyframe images** (í‚¤í”„ë ˆì„ë§Œ, ë¹„ë””ì˜¤ ì•„ë‹˜)
- 45 subjects
- 7 FMS actions Ã— 15 representations

**íŠ¹ì§•**:
- âœ… **LLM í†µí•©** (RTMPose + LLM)
- âœ… Hierarchical action annotations
- âœ… Expert rules + scoring criteria
- âš ï¸ **í‚¤í”„ë ˆì„ë§Œ** (ì „ì²´ ë¹„ë””ì˜¤ ì—†ìŒ)

**í‰ê°€ ë°©ì‹**:
- FMS score ì˜ˆì¸¡
- âŒ **Process Reward Model ì•„ë‹˜**

---

#### Azure Kinect FMS Dataset (2022)

**ì¶œì²˜**: [Functional movement screen dataset collected with two Azure Kinect depth sensors](https://www.nature.com/articles/s41597-022-01188-7)

**ê·œëª¨**:
- 45 participants
- 7 FMS movements
- 1,812 recordings (3,624 episodes)
- **158 GB**
- 2 Azure Kinect sensors (front + side view)

**íŠ¹ì§•**:
- âœ… Multi-modality (RGB + Depth)
- âœ… Multi-view
- âœ… ê³µê°œ ë°ì´í„°ì…‹

**í‰ê°€ ë°©ì‹**:
- Pose estimation
- âŒ **VQA í˜•ì‹ ì•„ë‹˜**

---

#### KneE-PAD (2025ë…„ 1ì›”) - **ì‹¤ì œ í™˜ì**

**ì¶œì²˜**: [A Knee Rehabilitation Exercises Dataset for Postural Assessment](https://www.nature.com/articles/s41597-025-04963-4)

**ê·œëª¨**:
- **31 patients with knee pathologies** ğŸ”¥
- **267 patient recordings**
- 3 exercises (squats, leg extension, walking)

**íŠ¹ì§•**:
- âœ… **ì‹¤ì œ í™˜ì ë°ì´í„°** (vs ê±´ê°•í•œ í”¼í—˜ì)
- âœ… sEMG + IMU sensors
- âœ… Correct + wrong variations

**í‰ê°€ ë°©ì‹**:
- Exercise correctness
- âŒ **ë‹¨ê³„ë³„ ì¶”ë¡  ì—†ìŒ**

---

#### UI-PRMD (2017) - **ìì£¼ ì¸ìš©ë¨**

**ì¶œì²˜**:
- [A Data Set of Human Body Movements for Physical Rehabilitation Exercises](https://pmc.ncbi.nlm.nih.gov/articles/PMC5773117/)
- [GitHub - avakanski/A-Deep-Learning-Framework](https://github.com/avakanski/A-Deep-Learning-Framework-for-Assessing-Physical-Rehabilitation-Exercises)

**ê·œëª¨**:
- 10 subjects
- 10 repetitions per movement
- Vicon optical tracker + Kinect

**ì¸ìš© ìˆ˜**: **200+ citations**

**íŠ¹ì§•**:
- âœ… ê³µê°œ ë°ì´í„°ì…‹
- âœ… Deep learning framework ì œê³µ
- âœ… **2023-2024ì—ë„ ê³„ì† ì¸ìš©ë¨**

**í‰ê°€ ë°©ì‹**:
- Quality score (ì—°ì†ê°’)
- âŒ **VQA í˜•ì‹ ì•„ë‹˜**

---

#### UCI Physical Therapy Exercises (2022)

**ì¶œì²˜**: [UCI ML Repository - Physical Therapy Exercises](https://archive.ics.uci.edu/dataset/730/physical+therapy+exercises+dataset)

**ê·œëª¨**:
- 5 subjects
- 8 exercises
- 3 execution types (correct, fast, low-amplitude)

**íŠ¹ì§•**:
- âœ… Creative Commons CC BY 4.0
- âš ï¸ **Wearable sensors** (accelerometer, gyroscope, magnetometer)

---

#### IntelliRehabDS (IRDS) (2021)

**ì¶œì²˜**: [IntelliRehabDS (IRDS)â€”A Dataset of Physical Rehabilitation Movements](https://www.mdpi.com/2306-5729/6/5/46)

**ê·œëª¨**:
- 10 exercises
- Kinect v2
- 29 subjects (15 patients + 14 healthy)

**íŠ¹ì§•**:
- Skeleton data
- âŒ ë¹„ë””ì˜¤ í’ˆì§ˆ ì œí•œì 

---

## Part 2: ì˜ë£Œ VQA ë²¤ì¹˜ë§ˆí¬ (5ê°œ)

### 2.1 PMC-VQA (2023) - **ì˜ë£Œ VQA ëŒ€í‘œ**

**ì¶œì²˜**: [PMC-VQA: Visual Instruction Tuning for Medical VQA](https://arxiv.org/html/2305.10415v6)

**ê·œëª¨**:
- **227,000 VQA pairs**
- 149,000 images
- 80% radiological images

**íŠ¹ì§•**:
- âœ… ëŒ€ê·œëª¨ ì˜ë£Œ VQA
- âš ï¸ **ì •ì  ì´ë¯¸ì§€ë§Œ** (ë¹„ë””ì˜¤ ì—†ìŒ)

**í‰ê°€ ë°©ì‹**:
- Final answer accuracy
- âŒ **ë‹¨ê³„ë³„ ì¶”ë¡  í‰ê°€ ì—†ìŒ**

---

### 2.2 VQA-RAD (Radiology VQA)

**ê·œëª¨**:
- 315 images
- 3,515 questions

**íŠ¹ì§•**:
- ë°©ì‚¬ì„  ì˜ìƒ ì „ë¬¸
- **ì •ì  ì´ë¯¸ì§€ë§Œ**

---

### 2.3 PathVQA (Pathology VQA)

**ê·œëª¨**:
- 32,795 QA pairs
- Pathological images

---

### 2.4 SLAKE

ì˜ë£Œ VQA í‘œì¤€ ë²¤ì¹˜ë§ˆí¬

---

### 2.5 EndoVis 2017 - **ìœ ì¼í•œ ë¹„ë””ì˜¤ VQA**

**ê·œëª¨**:
- 5 robotic surgery videos
- 472 QA pairs

**íŠ¹ì§•**:
- âœ… **ë¹„ë””ì˜¤ ë°ì´í„°** (ìœ ì¼)
- âš ï¸ **ìˆ˜ìˆ  ì˜ìƒ** (ë¬¼ë¦¬ì¹˜ë£Œ ì•„ë‹˜)
- âš ï¸ ë§¤ìš° ì‘ì€ ê·œëª¨

---

## Part 3: Process Reward Model ë²¤ì¹˜ë§ˆí¬

### 3.1 ğŸ† VisualPRM (2024) - **ë©€í‹°ëª¨ë‹¬ PRM ìµœì´ˆ**

**ì¶œì²˜**: [VisualPRM: An Effective Process Reward Model for Multimodal Reasoning](https://arxiv.org/abs/2503.10291)

**ê·œëª¨**:
- **VisualPRM400K** dataset
- 8B parameters PRM model
- **Human-annotated step-wise correctness labels**

**íŠ¹ì§•**:
- âœ… **Process Reward Model for multimodal reasoning**
- âœ… **Step-wise evaluation** â­
- âœ… **VisualProcessBench** (human-annotated benchmark)
- âœ… Best-of-N (BoN) evaluation strategy
- âŒ **ì¼ë°˜ ë„ë©”ì¸** (ë¬¼ë¦¬ì¹˜ë£Œ ì•„ë‹˜)
- âŒ **ë¹„ë””ì˜¤ ì•„ë‹˜** (ì •ì  ì´ë¯¸ì§€ ì¤‘ì‹¬)

**í‰ê°€ ë°©ì‹**:
- Step-wise correctness labels
- Best-of-N selection improvement

**ìš°ë¦¬ì™€ì˜ ì°¨ì´**:
```
VisualPRM (ì¼ë°˜):
- Domain: ì¼ë°˜ multimodal reasoning (MathVista, AI2D ë“±)
- Modality: ì •ì  ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸
- Task: ìˆ˜í•™, ê³¼í•™ ë¬¸ì œ í•´ê²°

PhysioMM-PRM (ìš°ë¦¬):
- Domain: ë¬¼ë¦¬ì¹˜ë£Œ ì„ìƒ ì¶”ë¡  â­
- Modality: ë¹„ë””ì˜¤ (70%) + ì´ë¯¸ì§€ (30%) â­
- Task: ì›€ì§ì„ í‰ê°€ + ì¹˜ë£Œ ê³„íš â­
```

---

### 3.2 MVBench (CVPR 2024) - **ë¹„ë””ì˜¤ ì´í•´**

**ì¶œì²˜**: [MVBench: A Comprehensive Multi-modal Video Understanding Benchmark](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_MVBench_A_Comprehensive_Multi-modal_Video_Understanding_Benchmark_CVPR_2024_paper.pdf)

**íŠ¹ì§•**:
- âœ… **20 challenging video understanding tasks**
- âœ… Temporal reasoning
- âŒ **PRM ë°©ì‹ ì•„ë‹˜** (ë‹¨ì¼ ë‹µë³€)
- âŒ **ì˜ë£Œ ë„ë©”ì¸ ì•„ë‹˜**

---

### 3.3 Video-MME (2024) - **ë¹„ë””ì˜¤ ë¶„ì„**

**ì¶œì²˜**: [Video-MME: The First-Ever Comprehensive Evaluation Benchmark](https://arxiv.org/abs/2405.21075)

**íŠ¹ì§•**:
- âœ… Multi-modal LLM í‰ê°€
- âŒ **PRM ë°©ì‹ ì•„ë‹˜**
- âŒ **ì˜ë£Œ ë„ë©”ì¸ ì•„ë‹˜**

---

## Part 4: ì˜ë£Œ ì„ìƒ ì¶”ë¡  í‰ê°€

### 4.1 NEJM AI - Script Concordance Testing (2024)

**ì¶œì²˜**: [Assessment of Large Language Models in Clinical Reasoning](https://ai.nejm.org/doi/full/10.1056/AIdbp2500120)

**ê·œëª¨**:
- **750 SCT questions**
- 10 international datasets
- Multiple specialties
- **ë¬¼ë¦¬ì¹˜ë£Œ í¬í•¨** â­

**í‰ê°€ ëŒ€ìƒ**:
- 10 LLMs
- 1,070 medical students (1,026 medical + **44 physiotherapy**)
- 193 residents
- 300 attending physicians

**íŠ¹ì§•**:
- âœ… **Step-wise clinical reasoning í‰ê°€**
- âœ… **ë¬¼ë¦¬ì¹˜ë£Œ í¬í•¨**
- âŒ **ë¹„ë””ì˜¤ ê¸°ë°˜ ì•„ë‹˜** (í…ìŠ¤íŠ¸ ì¤‘ì‹¬)
- âŒ **Process Reward Model ì•„ë‹˜**

---

## Part 5: ì¢…í•© ë¹„êµí‘œ

### 5.1 ì „ì²´ ë°ì´í„°ì…‹ ë¹„êµ

| ë°ì´í„°ì…‹ | ì—°ë„ | ê·œëª¨ | ìš´ë™/Action | ë¹„ë””ì˜¤ | VQA | PRM | í™˜ì | ì¸ìš© |
|---------|------|------|-------------|--------|-----|-----|------|------|
| **NTU RGB+D 120** | 2020 | 114K videos | 120 actions | âœ… | âŒ | âŒ | âŒ | 2,000+ |
| **NTU RGB+D** | 2016 | 56K videos | 60 actions | âœ… | âŒ | âŒ | âŒ | 4,000+ |
| **TheraPose** | 2024 | 3.4M frames | 123 exercises | âœ… | âŒ | âŒ | âŒ | - |
| **KIMORE** | 2019 | 78 subjects | 5 exercises | âœ… | âŒ | âŒ | âœ… | 300+ |
| **UCO** | 2023 | 2,160 seq | 8 exercises | âœ… | âŒ | âŒ | âŒ | - |
| **REHAB24-6** | 2024 | 184K frames | 6 exercises | âœ… | âŒ | âŒ | âŒ | - |
| **FineRehab** | 2024 | 4,215 files | 16 exercises | âœ… | âŒ | âŒ | âš ï¸ | - |
| **UI-PRMD** | 2017 | 10 subjects | 10 exercises | âœ… | âŒ | âŒ | âŒ | 200+ |
| **KneE-PAD** | 2025 | 267 patients | 3 exercises | âœ… | âŒ | âŒ | âœ… | - |
| **LLM-FMS** | 2025 | 1,812 frames | 7 FMS | âš ï¸ | âŒ | âŒ | âŒ | - |
| **Azure FMS** | 2022 | 1,812 rec | 7 FMS | âœ… | âŒ | âŒ | âŒ | - |
| **UCI PT** | 2022 | 5 subjects | 8 exercises | âš ï¸ | âŒ | âŒ | âŒ | - |
| **PMC-VQA** | 2023 | 227K pairs | - | âŒ | âœ… | âŒ | - | - |
| **VisualPRM** | 2024 | 400K | - | âŒ | âœ… | **âœ…** | âŒ | - |
| **PhysioMM-PRM (ìš°ë¦¬)** | 2026 | 10K Q | 5+ exercises | **âœ… 70%** | **âœ…** | **âœ…** | **âœ…** | - |

---

### 5.2 ë²¤ì¹˜ë§ˆí¬ ê¸°ëŠ¥ ë¹„êµ

| ë²¤ì¹˜ë§ˆí¬ | ë„ë©”ì¸ | ëª¨ë‹¬ë¦¬í‹° | PRM | Step-wise | VQA | ì¸ìš© |
|---------|--------|----------|-----|-----------|-----|------|
| **NTU RGB+D 120** | Action Recognition | Video | âŒ | âŒ | âŒ | 2,000+ |
| **KIMORE** | Rehabilitation | Video | âŒ | âŒ | âŒ | 300+ |
| **VisualPRM** | General Reasoning | Image | **âœ…** | **âœ…** | âœ… | New |
| **NEJM AI SCT** | Clinical Reasoning | Text | âŒ | **âœ…** | âŒ | New |
| **MVBench** | Video Understanding | Video | âŒ | âŒ | âœ… | New |
| **PhysioMM-PRM (ìš°ë¦¬)** | **Physiotherapy** | **Video** | **âœ…** | **âœ…** | **âœ…** | - |

---

## Part 6: í•µì‹¬ ì°¨ë³„ì  ë¶„ì„

### 6.1 ê¸°ì¡´ ì—°êµ¬ì˜ 4ê°€ì§€ ë°©í–¥

```
ë°©í–¥ 1: ì¬í™œ ìš´ë™ ë°ì´í„°ì…‹ (11ê°œ)
â†’ ëª©ì : Pose estimation, Activity recognition
â†’ í‰ê°€: Binary correctness, Quality score
â†’ í•œê³„: "ì™œ í‹€ë ¸ëŠ”ê°€?" ì„¤ëª… ë¶ˆê°€

ë°©í–¥ 2: ì˜ë£Œ VQA (5ê°œ)
â†’ ëª©ì : ì˜ë£Œ ì´ë¯¸ì§€ ì§ˆë¬¸-ë‹µë³€
â†’ í‰ê°€: Final answer accuracy
â†’ í•œê³„: ì •ì  ì´ë¯¸ì§€, ë‹¨ê³„ë³„ ì¶”ë¡  ì—†ìŒ

ë°©í–¥ 3: Process Reward Model (VisualPRM)
â†’ ëª©ì : ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ê³¼ì • í‰ê°€
â†’ í‰ê°€: Step-wise correctness
â†’ í•œê³„: ì¼ë°˜ ë„ë©”ì¸ (ìˆ˜í•™/ê³¼í•™), ì •ì  ì´ë¯¸ì§€

ë°©í–¥ 4: ì„ìƒ ì¶”ë¡  í‰ê°€ (NEJM AI SCT)
â†’ ëª©ì : ì˜ë£Œ ì˜ì‚¬ê²°ì • í‰ê°€
â†’ í‰ê°€: Script concordance
â†’ í•œê³„: í…ìŠ¤íŠ¸ ê¸°ë°˜, ë¹„ë””ì˜¤ ì—†ìŒ
```

### 6.2 ìš°ë¦¬ì˜ ë…ì ì  í¬ì§€ì…˜

**PhysioMM-PRM = 4ê°€ì§€ ë°©í–¥ì˜ êµì§‘í•©**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ì¬í™œ ìš´ë™ ë¹„ë””ì˜¤ (ë°©í–¥ 1)         â”‚
â”‚   âˆ©                                 â”‚
â”‚   ì˜ë£Œ VQA (ë°©í–¥ 2)                 â”‚
â”‚   âˆ©                                 â”‚
â”‚   Process Reward Model (ë°©í–¥ 3)     â”‚
â”‚   âˆ©                                 â”‚
â”‚   ì„ìƒ ì¶”ë¡  í‰ê°€ (ë°©í–¥ 4)           â”‚
â”‚                                     â”‚
â”‚   = PhysioMM-PRM (ìš°ë¦¬) â­          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**êµ¬ì²´ì  ì°¨ë³„ì **:

| íŠ¹ì„± | ê¸°ì¡´ ìµœì„  | PhysioMM-PRM |
|------|----------|--------------|
| **ë„ë©”ì¸** | ì¼ë°˜ action recognition (NTU RGB+D) | **ë¬¼ë¦¬ì¹˜ë£Œ ì„ìƒ ì¶”ë¡ ** â­ |
| **ëª¨ë‹¬ë¦¬í‹°** | ë¹„ë””ì˜¤ OR ì´ë¯¸ì§€ | **ë¹„ë””ì˜¤ (70%) + ì´ë¯¸ì§€ (30%)** â­ |
| **í‰ê°€ ë°©ì‹** | Outcome-based (VisualPRM: ì¼ë°˜ ë„ë©”ì¸) | **Process-based (ë¬¼ë¦¬ì¹˜ë£Œ ë„ë©”ì¸)** â­ |
| **VQA í˜•ì‹** | ìˆìŒ (PMC-VQA: ì •ì  ì´ë¯¸ì§€) | **âœ… ë¹„ë””ì˜¤ VQA** â­ |
| **Step-wise í‰ê°€** | ìˆìŒ (VisualPRM: ìˆ˜í•™/ê³¼í•™) | **âœ… ì„ìƒ ì¶”ë¡ ** â­ |
| **ì„ìƒ ì ìš©** | ì—†ìŒ | **âœ… PhysioKorea í†µí•©** â­ |

---

## Part 7: ê²½ìŸ ìš°ìœ„ ì „ëµ

### 7.1 ê¸°ìˆ ì  ìš°ìœ„

**1. VisualPRM ë°©ë²•ë¡  + ë¬¼ë¦¬ì¹˜ë£Œ ë„ë©”ì¸**:
- VisualPRMì€ ì¼ë°˜ ë„ë©”ì¸ì—ì„œ step-wise evaluation íš¨ê³¼ ì…ì¦
- ìš°ë¦¬: ë™ì¼ ë°©ë²•ë¡ ì„ ë¬¼ë¦¬ì¹˜ë£Œ ë„ë©”ì¸ì— ìµœì´ˆ ì ìš©
- **ì°¨ë³„í™”**: Domain specialization

**2. Med-PRM íš¨ìœ¨ì„± + ë¹„ë””ì˜¤ í™•ì¥**:
- Med-PRM: RAG-as-a-Judgeë¡œ $20 ë¹„ìš© (vs $1,443)
- ìš°ë¦¬: ë™ì¼ íš¨ìœ¨ì„±ì„ ë¹„ë””ì˜¤ë¡œ í™•ì¥ ($3,520)
- **ì°¨ë³„í™”**: Cost-efficient multimodal PRM

**3. í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼**:
- RAG-Judge (90% steps) + Monte Carlo (10% low-confidence)
- VisualPRM (ìˆœìˆ˜ Monte Carlo) ëŒ€ë¹„ 81% ë¹„ìš© ì ˆê°
- **ì°¨ë³„í™”**: Hybrid annotation quality + efficiency

### 7.2 ë…¼ë¬¸ í¬ì§€ì…”ë‹

**Title (ì œì•ˆ)**:
> "PhysioMM-PRM: First Process Reward Model Benchmark for Physiotherapy Video Understanding with Step-wise Clinical Reasoning"

**Abstract ì²« ë¬¸ì¥**:
> "While existing rehabilitation datasets focus on pose estimation and action recognition (NTU RGB+D, KIMORE), and Process Reward Models remain limited to general domains (VisualPRM), **we introduce the first PRM benchmark for physiotherapy** that evaluates step-wise clinical reasoning in video-based movement assessment."

**í•µì‹¬ ë©”ì‹œì§€**:
1. **First** PRM for physiotherapy domain
2. **Video-based** clinical reasoning (vs VisualPRM's static images)
3. **Hybrid annotation** (cost-efficient + high-quality)
4. **Real-world deployment** (PhysioKorea integration)

### 7.3 ì¸ìš© ì „ëµ

**Related Work êµ¬ì„±**:

```markdown
### 2.1 Rehabilitation Exercise Datasets
- NTU RGB+D [120]: Large-scale action recognition (114K videos)
- KIMORE [78]: Clinical rehabilitation assessment
- REHAB24-6 [65]: Exercise correctness evaluation
â†’ í•œê³„: Outcome-based evaluation, no step-wise reasoning

### 2.2 Medical VQA
- PMC-VQA [227K]: Medical image VQA
- EndoVis [472]: Surgical video VQA (only video VQA)
â†’ í•œê³„: Static images, final answer only

### 2.3 Process Reward Models
- VisualPRM [400K]: Multimodal PRM for general reasoning
- Math-Shepherd: Step-wise math reasoning
â†’ í•œê³„: General domain (math/science), static images

### 2.4 Clinical Reasoning Evaluation
- NEJM AI SCT [750]: Script concordance testing
â†’ í•œê³„: Text-based, no video

### 2.5 Our Contribution
PhysioMM-PRM uniquely combines:
1. Video-based multimodal input (70% video)
2. Step-wise clinical reasoning evaluation (PRM)
3. Physiotherapy domain expertise
4. Hybrid annotation (RAG + Monte Carlo)
```

---

## Part 8: ë¦¬ìŠ¤í¬ ì¬í‰ê°€

### 8.1 "VisualPRMì´ ì´ë¯¸ ì¡´ì¬" ë¦¬ìŠ¤í¬

**í‰ê°€**: **ë‚®ìŒ** âœ…

**ì´ìœ **:
1. VisualPRMì€ **ì¼ë°˜ ë„ë©”ì¸** (MathVista, AI2D ë“±)
2. ìš°ë¦¬ëŠ” **ë¬¼ë¦¬ì¹˜ë£Œ ë„ë©”ì¸** (ì™„ì „íˆ ë‹¤ë¥¸ ì‹œì¥)
3. VisualPRMì€ **ì •ì  ì´ë¯¸ì§€** ì¤‘ì‹¬
4. ìš°ë¦¬ëŠ” **ë¹„ë””ì˜¤ (70%)** ì¤‘ì‹¬

**ì°¨ë³„í™” ì „ëµ**:
- Related Workì—ì„œ VisualPRMì„ **ë°©ë²•ë¡  ì°¸ê³ **ë¡œ ì¸ìš©
- "We adapt VisualPRM's methodology to physiotherapy domain"
- Domain adaptationì˜ ì–´ë ¤ì›€ ê°•ì¡° (ì˜ë£Œ ì „ë¬¸ì„± í•„ìš”)

### 8.2 "NTU RGB+Dê°€ ì´ë¯¸ í¬ë‹¤" ë¦¬ìŠ¤í¬

**í‰ê°€**: **ë‚®ìŒ** âœ…

**ì´ìœ **:
1. NTU RGB+DëŠ” **ì¼ë°˜ action recognition** (120 daily actions)
2. ìš°ë¦¬ëŠ” **ì„ìƒ ì¶”ë¡ ** (ë³´ìƒ íŒ¨í„´ ì‹ë³„ + ì¹˜ë£Œ ê³„íš)
3. NTU RGB+DëŠ” **classification** (action label)
4. ìš°ë¦¬ëŠ” **VQA + PRM** (ì§ˆë¬¸-ì¶”ë¡ -ë‹µë³€)

**ì°¨ë³„í™” ì „ëµ**:
- "While NTU RGB+D provides action labels, we provide clinical reasoning process"

### 8.3 "ì¬í™œ ë°ì´í„°ì…‹ì´ ë§ë‹¤" ë¦¬ìŠ¤í¬

**í‰ê°€**: **ë§¤ìš° ë‚®ìŒ** âœ…

**ì´ìœ **:
- **11ê°œ ëª¨ë‘ VQA í˜•ì‹ ì•„ë‹˜**
- **11ê°œ ëª¨ë‘ PRM ë°©ì‹ ì•„ë‹˜**
- **11ê°œ ëª¨ë‘ ë‹¨ê³„ë³„ ì¶”ë¡  í‰ê°€ ì—†ìŒ**

**ìš°ë¦¬ì˜ ë…ì ì„±**:
```
ê¸°ì¡´ 11ê°œ ë°ì´í„°ì…‹:
- Input: Video
- Output: Class label OR Quality score

PhysioMM-PRM (ìš°ë¦¬):
- Input: Video + Clinical Question
- Output: Step-wise Reasoning + Answer + Treatment Plan
```

---

## Part 9: ì „ëµì  ì œì•ˆ

### 9.1 ì¦‰ì‹œ ì‹¤í–‰ í•­ëª© (Week 1-2)

**1. arXiv Preprint ì¡°ê¸° ê³µê°œ**:
- ëª©ì : ì„ ì  íš¨ê³¼ (first-mover advantage)
- ì‹œê¸°: MVP ë°ì´í„°ì…‹ ì™„ì„± ì¦‰ì‹œ (3,000 questions)
- ì „ëµ: "First PRM for Physiotherapy" ê°•ì¡°

**2. HuggingFace Dataset ì—…ë¡œë“œ**:
- ëª©ì : ê°€ì‹œì„± í™•ë³´, ì»¤ë®¤ë‹ˆí‹° í”¼ë“œë°±
- ì‹œê¸°: arXivì™€ ë™ì‹œ
- ì „ëµ: READMEì— VisualPRMê³¼ì˜ ì°¨ì´ ëª…í™•íˆ ê¸°ìˆ 

**3. í•µì‹¬ ë©”ì‹œì§€ í†µì¼**:
- Twitter/Reddit: "First Process Reward Model for Physiotherapy"
- GitHub README: "Video-based Clinical Reasoning Evaluation"
- Paper Title: "PhysioMM-PRM: First PRM Benchmark for Physiotherapy"

### 9.2 ë…¼ë¬¸ íˆ¬ê³  ì „ëµ

**ìš°ì„ ìˆœìœ„**:

1. **NeurIPS 2026 Datasets & Benchmarks Track** (ìµœìš°ì„ )
   - Deadline: ~2026ë…„ 5ì›”
   - ì´ìœ : ë°ì´í„°ì…‹ ë…¼ë¬¸ ìµœê³  venue
   - ê°•ì : "First PRM for physiotherapy" novelty

2. **CVPR 2027** (backup)
   - Deadline: ~2026ë…„ 11ì›”
   - Track: Vision for Healthcare

3. **ICCV 2027** (backup)
   - Medical Computer Vision

### 9.3 ì»¤ë®¤ë‹ˆí‹° ì „ëµ

**1. ê¸°ì¡´ ì—°êµ¬ìë“¤ê³¼ì˜ í˜‘ë ¥**:
- NTU RGB+D ì €ìì—ê²Œ ì—°ë½: "Extending your dataset to clinical reasoning"
- VisualPRM ì €ìì—ê²Œ ì—°ë½: "Applying your method to healthcare"

**2. ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬**:
- VisualPRM codebaseì— PR: "Physiotherapy domain adaptation"
- NTU RGB+D evaluation codeì— PR: "Clinical reasoning metrics"

---

## Part 10: ìµœì¢… ê²°ë¡ 

### 10.1 í•µì‹¬ ë°œê²¬ ìš”ì•½

| í•­ëª© | ë°œê²¬ | ì˜ë¯¸ |
|------|------|------|
| **ì¬í™œ ë°ì´í„°ì…‹** | 11ê°œ ì¡´ì¬ | âœ… ë„ë©”ì¸ í™œë°œ, âŒ PRM ì „ë¬´ |
| **ì˜ë£Œ VQA** | 5ê°œ ì¡´ì¬ | âœ… VQA ê²€ì¦ë¨, âŒ ë¹„ë””ì˜¤ ê±°ì˜ ì—†ìŒ |
| **PRM ë²¤ì¹˜ë§ˆí¬** | VisualPRM ì¡´ì¬ | âœ… ë°©ë²•ë¡  ê²€ì¦, âŒ ë¬¼ë¦¬ì¹˜ë£Œ ì „ë¬´ |
| **ì„ìƒ ì¶”ë¡ ** | NEJM AI SCT | âœ… ì˜ë£Œ ì ìš© ê²€ì¦, âŒ ë¹„ë””ì˜¤ ì—†ìŒ |
| **PhysioMM-PRM** | **ì „ë¬´** | **âœ… ì„¸ê³„ ìµœì´ˆ** â­â­â­ |

### 10.2 ê²½ìŸ ìš°ìœ„ í™•ì‹ ë„

**95% í™•ì‹ **: PhysioMM-PRMì€ **ì„¸ê³„ ìµœì´ˆ** ë¬¼ë¦¬ì¹˜ë£Œ ë„ë©”ì¸ Process Reward Model ë²¤ì¹˜ë§ˆí¬

**ê·¼ê±°**:
1. **11ê°œ ì¬í™œ ë°ì´í„°ì…‹** ëª¨ë‘ PRM ë°©ì‹ ì•„ë‹˜
2. **VisualPRM** ì¡´ì¬í•˜ì§€ë§Œ ì¼ë°˜ ë„ë©”ì¸ (ìˆ˜í•™/ê³¼í•™)
3. **NEJM AI SCT** ì˜ë£Œ ì¶”ë¡  í‰ê°€í•˜ì§€ë§Œ ë¹„ë””ì˜¤ ì—†ìŒ
4. **êµì§‘í•© (ì¬í™œ + VQA + PRM + ë¹„ë””ì˜¤)**: **ì „ë¬´**

### 10.3 í–‰ë™ ê³„íš

**ì¦‰ì‹œ (Week 1-2)**:
- âœ… ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ ì¡°ì‚¬ ì™„ë£Œ
- â³ PhysioKorea ë°ì´í„° ì¶”ì¶œ (100 videos)
- â³ Pilot ì§ˆë¬¸ ìƒì„± (10 questions)
- â³ ê¸°ìˆ  ìŠ¤íƒ ê²€ì¦ (GPT-4V, InternVL3, Gemini)

**ë‹¨ê¸° (Week 3-6)**:
- MVP ë°ì´í„°ì…‹ (3,000 questions)
- arXiv preprint ê³µê°œ
- HuggingFace dataset ì—…ë¡œë“œ

**ì¤‘ê¸° (Week 7-12)**:
- Full ë°ì´í„°ì…‹ (10,000 questions)
- NeurIPS 2026 D&B íˆ¬ê³ 
- ì»¤ë®¤ë‹ˆí‹° í”¼ë“œë°± ë°˜ì˜

---

## Part 11: ì£¼ìš” ì¸ìš© ì†ŒìŠ¤

### ì¬í™œ ë°ì´í„°ì…‹
- [NTU RGB+D (CVPR 2016)](https://arxiv.org/abs/1604.02808) - 4,000+ citations
- [NTU RGB+D 120 (TPAMI 2020)](https://arxiv.org/abs/1905.04757) - 2,000+ citations
- [KIMORE (TNSRE 2019)](https://www.researchgate.net/publication/333791841) - 300+ citations
- [UI-PRMD (2017)](https://pmc.ncbi.nlm.nih.gov/articles/PMC5773117/) - 200+ citations
- [REHAB24-6 (2024)](https://zenodo.org/records/13305826)
- [FineRehab (CVPR 2024)](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Li_FineRehab_A_Multi-modality_and_Multi-task_Dataset_for_Rehabilitation_Analysis_CVPRW_2024_paper.pdf)
- [UCO Physical Rehabilitation (2023)](https://www.mdpi.com/1424-8220/23/21/8862)
- [KneE-PAD (2025)](https://www.nature.com/articles/s41597-025-04963-4)
- [LLM-FMS (2025)](https://pmc.ncbi.nlm.nih.gov/articles/PMC11896072/)
- [Azure Kinect FMS (2022)](https://www.nature.com/articles/s41597-022-01188-7)

### Process Reward Models
- [VisualPRM (2024)](https://arxiv.org/abs/2503.10291)
- [Med-PRM (2024)](https://github.com/openmedlab/Med-PRM)

### ì˜ë£Œ VQA
- [PMC-VQA (2023)](https://arxiv.org/html/2305.10415v6)

### ì„ìƒ ì¶”ë¡ 
- [NEJM AI - Script Concordance Testing (2024)](https://ai.nejm.org/doi/full/10.1056/AIdbp2500120)

### ë¹„ë””ì˜¤ ì´í•´
- [MVBench (CVPR 2024)](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_MVBench_A_Comprehensive_Multi-modal_Video_Understanding_Benchmark_CVPR_2024_paper.pdf)
- [Video-MME (2024)](https://arxiv.org/abs/2405.21075)

---

---

## Part 12: Action Quality Assessment (AQA) - **ChatGPT ì¶”ê°€ ë°œê²¬**

### 12.1 AQA ë¶„ì•¼ ê°œìš”

**Action Quality Assessment (AQA)**: ì¸ê°„ ë™ì‘/í–‰ë™ì˜ í’ˆì§ˆì„ ì •ëŸ‰í™”í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•˜ëŠ” ì—°êµ¬ ë¶„ì•¼

**ì£¼ìš” ì‘ìš©**:
- ìŠ¤í¬ì¸  í›ˆë ¨ (ì˜¬ë¦¼í”½ ë‹¤ì´ë¹™, ì²´ì¡°)
- í”¼íŠ¸ë‹ˆìŠ¤ í‰ê°€
- ìˆ˜ìˆ  ìŠ¤í‚¬ í‰ê°€ (JIGSAWS)
- **ë¬¼ë¦¬ì¹˜ë£Œ ê°€ëŠ¥ì„± (ë¯¸ë˜ ì—°êµ¬)** â­

---

### 12.2 ì£¼ìš” AQA ë°ì´í„°ì…‹ (8ê°œ + Î±)

#### ğŸ† AQA-7 (2017) - **ì „í†µì  ë²¤ì¹˜ë§ˆí¬**

**ì¶œì²˜**: [AQA-7 Dataset](http://rtis.oit.unlv.edu/datasets/AQA-7.zip)

**ê·œëª¨**:
- **1,189 samples** (Winter + Summer Olympics)
- **7 action types**: Diving, Gymnastics, Skiing, Snowboarding, Trampoline

**ì¸ìš© ìˆ˜**: **500+ citations** (ì¶”ì •)

**íŠ¹ì§•**:
- âœ… AQA ë¶„ì•¼ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬
- âœ… Papers with Code SOTA: **84.0% Spearman correlation**
- âœ… ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” í‰ê°€ ê¸°ì¤€

**í‰ê°€ ë°©ì‹**:
- Score regression (0-10ì )
- âŒ **VQA í˜•ì‹ ì•„ë‹˜**
- âŒ **ë‹¨ê³„ë³„ ì¶”ë¡  ì—†ìŒ**

---

#### ğŸ† MTL-AQA (CVPR 2019) - **ê°€ì¥ ë§ì´ ì¸ìš©ë¨**

**ì¶œì²˜**:
- [What and How Well You Performed? A Multitask Learning Approach to Action Quality Assessment](https://arxiv.org/abs/1904.04346)
- [GitHub - ParitoshParmar/MTL-AQA](https://github.com/ParitoshParmar/MTL-AQA)

**ê·œëª¨**:
- **1,412 diving samples**
- 16 competitions
- Multi-task: Score + Fine-grained action recognition + Commentary generation

**ì¸ìš© ìˆ˜**: **300+ citations** (ì¶”ì •, ì €ì ì „ì²´ 753 citations)

**íŠ¹ì§•**:
- âœ… **Foundational work** in AQA (CVPR 2019)
- âœ… Largest multitask-AQA dataset (ë‹¹ì‹œ)
- âœ… Papers with Code SOTA: **95.1% Spearman correlation** ğŸ”¥
- âœ… Multi-task learning ë„ì…

**í‰ê°€ ë°©ì‹**:
- Multi-task: Score + Action class + Commentary
- âŒ **VQA í˜•ì‹ ì•„ë‹˜**
- âŒ **ë‹¨ê³„ë³„ ì¶”ë¡  ì—†ìŒ**

---

#### ğŸ† FineDiving (CVPR 2022 Oral) - **Fine-grained ì„ ë„**

**ì¶œì²˜**:
- [FineDiving: A Fine-grained Dataset for Procedure-aware Action Quality Assessment](https://arxiv.org/abs/2204.03646)
- [GitHub - xujinglin/FineDiving](https://github.com/xujinglin/FineDiving)
- [Project Page](https://sites.google.com/view/finediving)

**ê·œëª¨**:
- **3,000 videos** ğŸ”¥
- **52 action types**, 29 sub-action types, 23 difficulty levels
- Olympics, World Cup, World Championships, European Championships

**ì¸ìš© ìˆ˜**: **130+ citations**

**íŠ¹ì§•**:
- âœ… **Procedure-aware annotations** â­ (ë‹¨ê³„ë³„ ë¼ë²¨)
- âœ… **Fine-grained** (sub-action types)
- âœ… Step-level labels (consecutive steps)
- âœ… CVPR 2022 **Oral presentation**

**í‰ê°€ ë°©ì‹**:
- Score regression + Procedure-aware
- **ë‹¨ê³„ë³„ ë¼ë²¨ ì¡´ì¬** â­ (í•˜ì§€ë§Œ PRM ì•„ë‹˜)
- âŒ **VQA í˜•ì‹ ì•„ë‹˜**
- âŒ **ì„ìƒ ì¶”ë¡  ì—†ìŒ**

---

#### JIGSAWS - **ìˆ˜ìˆ  ìŠ¤í‚¬ í‰ê°€**

**ì¶œì²˜**: JHU-ISI Gesture and Skill Assessment Working Set

**íŠ¹ì§•**:
- âœ… **ì˜ë£Œ ë„ë©”ì¸** (ìˆ˜ìˆ )
- âœ… Surgical skills assessment
- âŒ **ì¬í™œ ì•„ë‹˜**

---

#### Fis-V - **í”¼ê²¨ ìŠ¤ì¼€ì´íŒ…**

**íŠ¹ì§•**:
- Figure skating jumps
- Short and long-term AQA

---

#### ğŸ† LOGO (CVPR 2023) - **ê¸´ ë¹„ë””ì˜¤, ê·¸ë£¹ AQA**

**ì¶œì²˜**:
- [LOGO: A Long-Form Video Dataset for Group Action Quality Assessment](https://arxiv.org/abs/2404.05029)
- [GitHub - shiyi-zh0408/LOGO](https://github.com/shiyi-zh0408/LOGO)

**ê·œëª¨**:
- **200 videos**
- **í‰ê·  204.2ì´ˆ** (ê¸´ ë¹„ë””ì˜¤) ğŸ”¥
- 26 artistic swimming events
- 8 athletes per sample

**íŠ¹ì§•**:
- âœ… **Multi-person** (ê·¸ë£¹ í‰ê°€)
- âœ… **Long-form video** (3ë¶„+ ì˜ìƒ)
- âœ… Formation labels (ê·¸ë£¹ ì •ë³´)
- âœ… Procedure annotations

**í‰ê°€ ë°©ì‹**:
- Group action quality
- âŒ **VQA í˜•ì‹ ì•„ë‹˜**

---

#### ğŸ† LucidAction (NeurIPS 2024) - **Multi-view**

**ì¶œì²˜**: [LucidAction: A Hierarchical and Multi-model Dataset](https://openreview.net/forum?id=ji5isUwL3r)

**ê·œëª¨**:
- **8 diverse sports**
- 4 curriculum levels
- Multi-view RGB video
- **2D + 3D pose sequences** ğŸ”¥

**íŠ¹ì§•**:
- âœ… **Multi-view** (ì—¬ëŸ¬ ì¹´ë©”ë¼)
- âœ… **Multi-modal** (RGB + 2D/3D pose)
- âœ… Hierarchical structure
- âœ… NeurIPS 2024 (ìµœì‹ )

**í‰ê°€ ë°©ì‹**:
- Quality scoring
- âŒ **VQA í˜•ì‹ ì•„ë‹˜**

---

#### ğŸ† FLEX (2024) - **í”¼íŠ¸ë‹ˆìŠ¤, Multi-modal**

**ì¶œì²˜**: [FLEX: A Large-Scale Multi-Modal Multi-Action Dataset](https://arxiv.org/abs/2506.03198)

**ê·œëª¨**:
- **7,500+ recordings** ğŸ”¥ (ê°€ì¥ í¼)
- **20 weight-loaded exercises**
- **38 subjects** (diverse skill levels)

**íŠ¹ì§•**:
- âœ… **Multi-modal**: RGB + 3D pose + **sEMG + physiological signals** ğŸ”¥
- âœ… **Multi-view** videos
- âœ… Synchronized data
- âœ… **í”¼íŠ¸ë‹ˆìŠ¤ ë„ë©”ì¸** (ë¬¼ë¦¬ì¹˜ë£Œì™€ ìœ ì‚¬)
- âœ… **ì„¸ê³„ ìµœì´ˆ** multi-modal fitness AQA

**í‰ê°€ ë°©ì‹**:
- Fitness action quality
- âŒ **VQA í˜•ì‹ ì•„ë‹˜**
- âŒ **ì„ìƒ ì¶”ë¡  ì—†ìŒ**

---

### 12.3 ğŸ† 2025ë…„ ì„œë² ì´ ë…¼ë¬¸ - **AQA ë¶„ì•¼ ì¢…í•©**

**"A Decade of Action Quality Assessment: Largest Systematic Survey"**

**ì¶œì²˜**:
- [arXiv:2502.02817](https://arxiv.org/abs/2502.02817) (2025ë…„ 2ì›” 5ì¼ ë°œí‘œ!)
- [GitHub Repository](https://github.com/HaoYin116/Survey_of_AQA)
- [Project Website](https://haoyin116.github.io/Survey_of_AQA/)

**ê·œëª¨**:
- **200+ ë…¼ë¬¸** ì²´ê³„ì  ë¦¬ë·°
- **PRISMA framework** ì‚¬ìš©
- **195 papers** ìµœì¢… ì„ ì •
- **26ê°œ ë°ì´í„°ì…‹** ë¶„ì„

**í•µì‹¬ ë°œê²¬**:
- âœ… AQA ë¶„ì•¼ 10ë…„ ì—­ì‚¬ ì •ë¦¬
- âœ… ìŠ¤í¬ì¸ /í”¼íŠ¸ë‹ˆìŠ¤ ì¤‘ì‹¬ ë°œì „
- âœ… **ì˜ë£Œ ì¬í™œ/ê¸°ëŠ¥ í‰ê°€ ê°€ëŠ¥ì„± ì–¸ê¸‰** â­
- âŒ **ì„ìƒ ì¶”ë¡ ê³¼ ì—°ê²°ëœ ì‚¬ë¡€ ê±°ì˜ ì—†ìŒ** â­

**2025 ì„œë² ì´ê°€ ì§€ì í•œ Gap**:
> "AQAëŠ” low-cost physiotherapy, sports training, workforce developmentì— far-reaching implicationsì„ ê°€ì§"
> "**ì„ìƒ ì¬í™œ ë™ì‘ í‰ê°€ ìˆ˜ì¤€ê³¼ ì§ˆì /ê·¼ê±° ê¸°ë°˜ ì„ìƒ Reasoning QA ê²°í•© ì‚¬ë¡€ëŠ” ê±°ì˜ ì—†ìŒ**"

---

### 12.4 AQA vs PhysioMM-PRM ë¹„êµ

#### AQA íŒ¨ëŸ¬ë‹¤ì„ (ê¸°ì¡´)

```python
# ê¸°ì¡´ AQA ì ‘ê·¼
input = video  # ìŠ¤í¬ì¸ /í”¼íŠ¸ë‹ˆìŠ¤ ì˜ìƒ
output = {
    "quality_score": 9.2,  # 0-10ì 
    "procedure_labels": ["step1", "step2", "step3"]  # FineDivingë§Œ
}

task = "How well?" (ì–¼ë§ˆë‚˜ ì˜í•˜ëŠ”ê°€?)
goal = ì ìˆ˜ ë¶€ì—¬ (scoring)
```

**íŠ¹ì§•**:
- âœ… Fine-grained annotations (FineDiving)
- âœ… Multi-modal (FLEX: RGB+sEMG)
- âœ… Multi-view (LucidAction)
- âœ… Long-form (LOGO: 200ì´ˆ+)
- âœ… Procedure-aware (ë‹¨ê³„ë³„ ë¼ë²¨)
- âŒ **VQA í˜•ì‹ ì•„ë‹˜**
- âŒ **PRM ë°©ì‹ ì•„ë‹˜**
- âŒ **ì„ìƒ ì¶”ë¡  ì—†ìŒ**
- âŒ **ì¹˜ë£Œ ê³„íš ì—†ìŒ**

---

#### PhysioMM-PRM íŒ¨ëŸ¬ë‹¤ì„ (ìš°ë¦¬)

```python
# ìš°ë¦¬ PRM ì ‘ê·¼
input = {
    "video": video,
    "clinical_question": "í™˜ìì˜ ìŠ¤ì¿¼íŠ¸ íŒ¨í„´ì„ í‰ê°€í•˜ê³  ì¹˜ë£Œ ì „ëµì„ ì œì‹œí•˜ì„¸ìš”"
}

output = {
    "step_wise_reasoning": [
        "Step 1: í•˜ê°• ë‹¨ê³„ì—ì„œ ë¬´ë¦ ë‚´ë°˜ ê´€ì°° âœ…",
        "Step 2: ë°œëª© ë°°ì¸¡êµ´ê³¡ ì œí•œ ì‹ë³„ âœ…",
        "Step 3: ê³ ê´€ì ˆ ì™¸íšŒì „ê·¼ ì•½í™” ì¶”ì • âœ…",
        "Step 4: ACL ì¬ê±´ìˆ  ë³‘ë ¥ê³¼ ì—°ê´€ âœ…",
        "Step 5: ì¹˜ë£Œ ìš°ì„ ìˆœìœ„ ê²°ì • âœ…"
    ],
    "compensation_pattern": "ë¬´ë¦ ë‚´ë°˜ + ë°œëª© ì œí•œ",
    "biomechanical_cause": "ë°œëª© ê°€ë™ì„± ì œí•œ â†’ ê·¼ìœ„ë¶€ ë³´ìƒ",
    "treatment_plan": [
        "1ìˆœìœ„: ë°œëª© ê°€ë™ì„± ìš´ë™",
        "2ìˆœìœ„: ê³ ê´€ì ˆ ì™¸ì „ê·¼ ê°•í™”",
        "3ìˆœìœ„: ê¸°ëŠ¥ì  ìŠ¤ì¿¼íŠ¸ ì¬êµìœ¡"
    ],
    "quality_score": 4.5  # (ì„ íƒì‚¬í•­)
}

task = "Why wrong? What's the problem? How to fix?"
      (ì™œ í‹€ë ¸ê³ , ë¬´ì—‡ì´ ë¬¸ì œì´ë©°, ì–´ë–»ê²Œ ê³ ì¹˜ëŠ”ê°€?)
goal = ì„ìƒ ì¶”ë¡  + ì¹˜ë£Œ ê³„íš (clinical reasoning + treatment planning)
```

**ì°¨ë³„í™”**:
- âœ… **VQA í˜•ì‹** (ì§ˆë¬¸-ì¶”ë¡ -ë‹µë³€)
- âœ… **Process Reward Model** (step-wise correctness labels)
- âœ… **ì„ìƒ ì¶”ë¡ ** (ë³´ìƒ íŒ¨í„´, ìƒì²´ì—­í•™ì  ì›ì¸)
- âœ… **ì¹˜ë£Œ ê³„íš** (actionable feedback)
- âœ… **ì˜ë£Œ ì „ë¬¸ì„±** (PhysioKorea í†µí•©)

---

### 12.5 AQA ë°ì´í„°ì…‹ ë¹„êµí‘œ

| ë°ì´í„°ì…‹ | ì—°ë„ | ê·œëª¨ | ë„ë©”ì¸ | Procedure-aware | Multi-modal | ì¸ìš© (ì¶”ì •) |
|---------|------|------|--------|----------------|------------|------------|
| **AQA-7** | 2017 | 1,189 | ìŠ¤í¬ì¸  | âŒ | âŒ | 500+ |
| **MTL-AQA** | 2019 | 1,412 | ë‹¤ì´ë¹™ | âŒ | âœ… (Multi-task) | 300+ |
| **FineDiving** | 2022 | 3,000 | ë‹¤ì´ë¹™ | **âœ…** â­ | âŒ | 130+ |
| **JIGSAWS** | - | - | ìˆ˜ìˆ  | âŒ | âœ… | - |
| **Fis-V** | - | - | í”¼ê²¨ | âŒ | âŒ | - |
| **LOGO** | 2023 | 200 | ì˜ˆìˆ  ìˆ˜ì˜ | âœ… | âŒ | New |
| **LucidAction** | 2024 | - | 8 sports | âŒ | **âœ… (Multi-view)** | New |
| **FLEX** | 2024 | **7,500** | í”¼íŠ¸ë‹ˆìŠ¤ | âŒ | **âœ… (sEMG)** ğŸ”¥ | New |

---

### 12.6 í•µì‹¬ Gap (2025 ì„œë² ì´ ì§€ì )

**ì¡´ì¬í•˜ëŠ” ê²ƒ** âœ…:
```
AQA ì—°êµ¬ (26ê°œ ë°ì´í„°ì…‹):
- ìŠ¤í¬ì¸ /ì²´ì¡°/í”¼íŠ¸ë‹ˆìŠ¤ ì¤‘ì‹¬
- ê¸°ìˆ  ìˆ˜ì¤€ í‰ê°€ (0-10ì )
- Procedure-aware annotations (FineDiving)
- Multi-modal (FLEX: RGB+sEMG)
- ì¼ë¶€ ì˜ë£Œ skill í‰ê°€ (JIGSAWS: ìˆ˜ìˆ )
```

**ë¶€ì¡±í•œ ê²ƒ** âŒ:
```
ì„ìƒ ì¬í™œ + ì§ˆì  ì¶”ë¡ :
- Movement quality score â†’ ì„ìƒì  íŒë‹¨ ì—°ê²° ê³ ë¦¬ ì—†ìŒ â­
- ê¸°ëŠ¥ ë³€í™” ì˜ˆì¸¡ ë°ì´í„° ì—†ìŒ â­
- "ì™œ í‹€ë ¸ëŠ”ê°€?" ì„¤ëª… ë¶ˆê°€ â­
- ì¹˜ë£Œ ê³„íš ì œì‹œ ì—†ìŒ â­
- ê³µì¸ëœ ê³µê°œ ë°ì´í„° ì „ë¬´ â­
```

---

### 12.7 ìš°ë¦¬ì˜ ë…ì ì  í¬ì§€ì…˜ (ì—…ë°ì´íŠ¸)

**PhysioMM-PRM = AQAì˜ Gapì„ ì±„ì›€**

```
AQA (ê¸°ì¡´):
â”œâ”€ Procedure-aware (FineDiving) âœ…
â”œâ”€ Multi-modal (FLEX) âœ…
â”œâ”€ Multi-view (LucidAction) âœ…
â””â”€ í•˜ì§€ë§Œ...
    âŒ ì ìˆ˜ë§Œ ì¤Œ (no reasoning)
    âŒ VQA í˜•ì‹ ì•„ë‹˜
    âŒ PRM ë°©ì‹ ì•„ë‹˜
    âŒ ì„ìƒ ì¶”ë¡  ì—†ìŒ

PhysioMM-PRM (ìš°ë¦¬):
â”œâ”€ AQAì˜ ì¥ì  ìƒì†
â”‚  â”œâ”€ Video-based âœ…
â”‚  â”œâ”€ Procedure-aware âœ…
â”‚  â””â”€ Multi-modal âœ…
â””â”€ Gap í•´ê²° â­
   â”œâ”€ VQA í˜•ì‹ âœ…
   â”œâ”€ Process Reward Model âœ…
   â”œâ”€ Step-wise clinical reasoning âœ…
   â””â”€ Treatment planning âœ…
```

---

### 12.8 AQA ì£¼ìš” ì¸ìš© ì†ŒìŠ¤

- [AQA-7 Dataset Download](http://rtis.oit.unlv.edu/datasets/AQA-7.zip)
- [MTL-AQA (CVPR 2019) - arXiv](https://arxiv.org/abs/1904.04346)
- [MTL-AQA - GitHub](https://github.com/ParitoshParmar/MTL-AQA)
- [FineDiving (CVPR 2022) - arXiv](https://arxiv.org/abs/2204.03646)
- [FineDiving - GitHub](https://github.com/xujinglin/FineDiving)
- [LOGO (CVPR 2023) - arXiv](https://arxiv.org/abs/2404.05029)
- [LucidAction (NeurIPS 2024) - OpenReview](https://openreview.net/forum?id=ji5isUwL3r)
- [FLEX (2024) - arXiv](https://arxiv.org/abs/2506.03198)
- [A Decade of AQA Survey (2025) - arXiv](https://arxiv.org/abs/2502.02817)
- [Awesome-AQA - GitHub](https://github.com/ZhouKanglei/Awesome-AQA)

---

**ë¬¸ì„œ ë²„ì „**: 3.0
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2026-01-08 23:45 (AQA ì„¹ì…˜ ì¶”ê°€)
**ìƒíƒœ**: âœ… ì¡°ì‚¬ ì™„ë£Œ - ì§„í–‰ ê°•ë ¥ ì¶”ì²œ

**ë‹¤ìŒ ë‹¨ê³„**: Week 1-2 êµ¬í˜„ ì‹œì‘ (PhysioKorea ë°ì´í„° ì¶”ì¶œ)
