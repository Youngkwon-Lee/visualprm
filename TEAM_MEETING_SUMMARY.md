# Med-PRM 실험 진행상황 팀 회의 자료

**작성일**: 2026-01-15
**프로젝트**: Med-PRM (Medical Reasoning Models with Stepwise, Guideline-verified Process Rewards)
**논문**: arXiv 2506.11474v2

---

## 📋 Executive Summary

Med-PRM 논문의 결과를 재현하기 위한 실험을 진행 중입니다.
- **현재 상태**: 첫 번째 전체 점수 계산 중 (72% 완료)
- **주요 발견**: 데이터셋 검증 및 토큰 제한 최적화 진행 완료
- **다음 단계**: 현재 실험 완료 후 재처리 필요

---

## 🎯 프로젝트 목표

1. **Med-PRM 재현**: 논문의 의료 프로세스 리워드 모델 성능 검증
2. **ProcessBench 평가**: 첫 오류 감지 능력 평가
3. **모델 검증**: Llama-3.1-8B 기반 의료 추론 평가

---

## 📊 실험 설정

### 모델 정보
- **PRM 모델**: `dmis-lab/llama-3.1-medprm-reward-v1.0`
- **기반 모델**: Llama-3.1-8B-Instruct
- **방식**: RAG-as-a-Judge (문서 기반 스텝 검증)

### 평가 지표
| 지표 | 의미 | 기대값 |
|------|------|--------|
| **MV** (Majority Voting) | 64개 생성 답변 중 가장 많은 것 선택 | ~66-68% |
| **BoN** (Best-of-N) | PRM 점수 최고 답변 선택 | ~77-78% |
| **Min P(+)** | 각 솔루션의 최소 스텝 확률 (첫 오류 감지) | ~77-78% |

---

## ✅ 완료된 작업

### 1️⃣ 데이터셋 검증 (✓ 완료)
**원본 논문 테스트 데이터 발견**
```
위치: /home2/gun3856/med-prm-vl/dataset/...
파일: 2_test_dataset.json + 2_test_dataset_part2.json
규모: 총 8,204개 질문
```

**데이터 구성 분석**
| 벤치마크 | 개수 | 논문값 | 비고 |
|---------|------|--------|------|
| MedQA-4op | 2,546 | 2,546 | ✓ 일치 |
| MedQA-5 | 1,273 | 1,273 | ✓ 일치 |
| MMLU의료 | 2,178 | 1,089 | ⚠️ 2배 (더 포함) |
| DDXPlus | 539 | 500 | ⚠️ 39개 추가 |
| 기타 | 1,068 | - | PubMedQA, OSCE 등 |

### 2️⃣ 토큰 제한 최적화 (✓ 완료)
**문제**: 3,200 토큰 제한에서 연속 스킵 발생
```
원인: RAG 문서 + 질문 + 솔루션이 초과
- 토큰 제한: 4,096
- 질문/솔루션 예약: 1,024
- RAG 문서 공간: 3,072 (부족)
```

**해결**: 토큰 제한을 4,096으로 증가
```python
# Line 170 in 4_scoring_PRM.py
if input_ids.size(1) > 4096:  # 원래 3200 → 4096 변경
    return None
```

### 3️⃣ 모델 검증 (✓ 완료)
- ✅ 모델이 올바르게 +/- 확률 계산
- ✅ 정답과 오답 구분 정확함
- ✅ Min P(+) 값 의미 있음 (0.88 vs 0.1)

---

## 🔄 최종 결과 (2026-01-16 완료)

### 실험 완료
**스크립트**: `4_scoring_PRM_checkpoint.py`
**입력**: `input.json` (혼합 5,469개)
**실행 시간**: 64시간 45분 54초
**상태**: ✅ 완료

**최종 결과**
```
MV (Majority Voting):   72.3% (3,954/5,469) ✓
PRM (Best-of-N):        22.1% (1,207/5,469) ⚠️ 낮음
```

**결과 해석**:
- **MV**: 예상 66-68% vs 실제 72.3% → **초과 달성** ✓
- **PRM**: 예상 77-78% vs 실제 22.1% → **심각한 미흡** ❌

⚠️ **PRM 정확도 문제의 원인**:
- 토큰 스킵으로 인한 -inf 값 저장
- 약 1,000+개 솔루션이 점수 계산 실패
- BoN 계산에서 제외되어 정확도 폭락

---

## 🔧 발견된 문제 및 해결 방안

### 문제 1: PRM 정확도 낮음
| 항목 | 값 |
|------|-----|
| 실제 | 22.1% (1,207/5,469) |
| 기대 | 77-78% |
| 손실 | 약 55% 포인트 |

**원인 분석**:
- 토큰 제한 설정 오류 (4096 설정 미반영)
- 약 1,000+개 솔루션에서 스킵 발생
- -inf 점수 저장으로 BoN 계산에서 제외

**해결 방안**:
```
1단계: 스킵된 항목 추출 및 분석
2단계: 토큰 제한 정확히 5000 이상으로 설정
3단계: 스킵된 항목만 재처리 (~15-20시간)
4단계: 최종 PRM 정확도 재계산
```

---

## 📋 다음 단계 (우선순위)

### 1️⃣ 즉시 (필수)
**작업**: 스킵된 항목 추출 및 검증 스크립트 실행
- `verify_calculation.py`: MV/PRM 계산 로직 검증
- `extract_skipped.py`: 스킵된 1,000+개 항목 추출
- `check_retest_feasibility.py`: 재테스트 가능성 분석
**예상 시간**: 1시간 (분석만)

### 2️⃣ 토큰 제한 수정 후 재실행 (권장)
**작업**: 토큰 제한을 4096 → 5000+ 으로 수정
```
python 4_scoring_PRM.py \
  --use_rag yes \
  --max_token_len 5000
```
**예상 시간**: ~65시간 (전체)
**기대 결과**: PRM 정확도 70%+ 달성

### 3️⃣ 스킵된 항목만 재처리 (빠른 방안)
**작업**: 스킵된 항목들 필터링 → 재실행
**데이터**: 스킵된 1,000+개 솔루션만
**예상 시간**: ~15-20시간
**효율성**: 높음 (전체 재실행 필요 없음)

### 4️⃣ MedQA-4만 테스트 (병렬 진행 가능)
```
데이터: MedQA-4op 2,546개 선택
시간: ~30시간
비교: 논문 76.76% (BoN)과 직접 비교
```

---

## 📈 실행 경로 선택

### 경로 A: 스킵 재처리 (권장, 가장 빠름)
| 단계 | 작업 | 시간 | 상태 |
|------|------|-----|------|
| 1 | 검증 스크립트 실행 | 1h | ✅ 즉시 |
| 2 | 스킵 항목 추출 | - | ✅ 자동 |
| 3 | 스킵 항목만 재처리 | 15h | ⏸️ 선택 |
| **합계** | | **16h** | |

### 경로 B: 전체 재실행 (안전함)
| 단계 | 작업 | 시간 | 상태 |
|------|------|-----|------|
| 1 | 토큰 제한 수정 | 0.5h | ⏸️ 선택 |
| 2 | 전체 재실행 | 65h | ⏸️ 선택 |
| **합계** | | **65.5h** | |

### 경로 C: MedQA-4 빠른 검증 (병렬 가능)
| 단계 | 작업 | 시간 | 상태 |
|------|------|-----|------|
| 1 | MedQA-4 필터링 | 1h | ⏸️ 선택 |
| 2 | 단일 벤치마크 실행 | 30h | ⏸️ 선택 |
| **합계** | | **31h** | |

**권장**: 경로 A(16h) → 경로 C(30h 병렬) → 경로 B(65h 최종)

---

## 🎓 기술적 배경

### Med-PRM이란?
의료 도메인을 위한 프로세스 리워드 모델로, 단순히 최종 답변만 평가하는 것이 아니라 **각 추론 스텝의 정확성을 평가**합니다.

```
입력: [의료 질문] + [RAG 문서] + [추론 단계]
     ↓
모델: Llama-3.1-8B (의료 미세조정)
     ↓
출력: 각 단계의 +/- 확률
     ↓
평가: Min P(+) = 첫 오류 감지 (ProcessBench)
```

### RAG (Retrieval-Augmented Generation)
```
질문 → 의료 문서 검색 → 문서 기반 검증
```
- 목적: 각 추론 스텝이 실제 의료 가이드라인에 부합하는지 확인
- 토큰 예산: 3,072개 (4,096 총 - 1,024 질문/솔루션)

---

## 💾 주요 파일 위치

| 파일 | 위치 | 용도 |
|------|------|------|
| 메인 스크립트 | `4_scoring_PRM.py` | PRM 점수 계산 |
| 데이터 (원본) | `2_test_dataset.json` (HPC) | 논문 테스트 셋 |
| 데이터 (현재) | `input.json` | 혼합 데이터 |
| 체크포인트 | `4_scoring_PRM_checkpoint.py` | 중단/재개 기능 |

---

## ❓ 회의 시 논의 항목

1. **현재 실험 완료 후 스킵 재처리**: 20시간 투자 여부?
2. **재실험 데이터셋 선택**: 옵션A (30h) vs 옵션B (120h)?
3. **ProcessBench 평가**: Phase 3로 진행할지?
4. **일정 조율**: 이 주/다음 주 중 언제 진행?

---

## 📌 주요 결론

✅ **완료됨**
- 모델 검증: 정상 작동
- 토큰 최적화: 4,096으로 설정
- 데이터 검증: 원본 논문 셋 확인

⏳ **진행 중**
- 현재 실험: 72% 진행, ~10시간 남음

⚠️ **해결 필요**
- PRM 정확도: 25.3% → 77-78%로 개선 필요
- 스킵 항목 재처리: 약 20시간 소요

🎯 **다음 단계**: 팀 회의에서 옵션 A/B 선택 후 진행

---

**문의**: 자세한 기술적 내용이나 추가 분석 필요 시 별도 회의

